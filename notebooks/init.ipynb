{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc91ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8717141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"ollama_chat/gpt-oss:20b\", api_base=\"http://localhost:11434\", api_key=\"fake\")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae7516",
   "metadata": {},
   "source": [
    "To invoke the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb49a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"There are **3** 'r's in the word *strawberry*.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(messages=[{\"role\": \"user\", \"content\": \"Hi! How many 'r's are there in strawberry?\"}])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbcfcb",
   "metadata": {},
   "source": [
    "# 1. Inline signatures\n",
    "\n",
    "Declare signatures inline using strings and arrows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4231db3",
   "metadata": {},
   "source": [
    "## Chain Of Thought\n",
    "GPT-oss has a 128k context window! Let's make it summarize some documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1780c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"../docs\"):\n",
    "    os.makedirs(\"../docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b65dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-12 22:01:54--  https://arxiv.org/pdf/2505.20286\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.195.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1113373 (1.1M) [application/pdf]\n",
      "Saving to: ‘../docs/alita_paper.pdf’\n",
      "\n",
      "../docs/alita_paper 100%[===================>]   1.06M  5.12MB/s    in 0.2s    \n",
      "\n",
      "2025-08-12 22:01:54 (5.12 MB/s) - ‘../docs/alita_paper.pdf’ saved [1113373/1113373]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://arxiv.org/pdf/2505.20286 -O \"../docs/alita_paper.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f84ea038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "docs = SimpleDirectoryReader(\"../docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9981cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Doc ID: 3ae54dff-0494-4fdf-83df-2c754f5c6576\n",
       "Text: arXiv:2505.20286v1  [cs.AI]  26 May 2025 ALITA : G ENERALIST\n",
       "AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION\n",
       "AND MAXIMAL SELF -EVOLUTION Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng\n",
       "Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin\n",
       "Yao1, Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1,\n",
       "Yue Wu1, Kaixua..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(str(docs[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d50f5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e89b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize = dspy.ChainOfThought('full_document -> summary')\n",
    "response = summarize(full_document = doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a6e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alita successfully generated a YouTube Video Subtitle Crawler MCP, executed it to retrieve the transcript of the specified 360 VR video, and extracted the correct number “100000000” mentioned by the narrator after the dinosaur scene. The workflow involved MCP brainstorming, web search for an open‑source tool, environment setup, code generation, MCP packaging, and final answer extraction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7681a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The case study demonstrates Alita’s workflow for extracting a specific piece of information from a YouTube 360 VR video. The process begins with an MCP Brainstorming step, where Alita identifies the need for a “YouTube Video Subtitle Crawler” MCP to automate subtitle extraction. The Web Agent then searches open‑source repositories and locates the `youtube-transcript-api` library on GitHub. The Manager Agent synthesizes this information, writes a Python function that uses the API to fetch the transcript, and generates environment setup instructions (conda environment creation and pip install). Once the code is executed in the prepared environment, the Manager Agent packages the function into the MCP, which is then used to scrape the subtitles from the target video. By parsing the transcript, Alita identifies the number “100000000” mentioned immediately after the dinosaurs are first shown. This answer matches the correct answer provided in the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.reasoning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c245e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-12T22:01:59.599782]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `full_document` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `summary` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## full_document ## ]]\n",
      "{full_document}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## summary ## ]]\n",
      "{summary}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `full_document`, produce the fields `summary`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## full_document ## ]]\n",
      "arXiv:2505.20286v1  [cs.AI]  26 May 2025\n",
      "ALITA : G ENERALIST AGENT ENABLING SCALABLE AGENTIC\n",
      "REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL\n",
      "SELF -EVOLUTION\n",
      "Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin Yao1,\n",
      "Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1, Yue Wu1, Kaixuan Huang1, Shilong Liu1,\n",
      "Hongru Wang6, Mengdi Wang1\n",
      "1AI Lab, Princeton University 2IIIS, Tsinghua University 3Shanghai Jiao Tong University\n",
      "4University of Michigan 5Tianqiao and Chrissy Chen Institute 6The Chinese University of Hong Kong\n",
      "0.3 0.4 0.5 0.6 0.7 0.8 0.9\n",
      "Average\n",
      "Level 3\n",
      "Level 2\n",
      "Level 1\n",
      "87.3%\n",
      "76.9%\n",
      "89.5%\n",
      "88.7%\n",
      "73.3%\n",
      "57.7%\n",
      "70.1%\n",
      "86.5%\n",
      "67.4%\n",
      "47.6%\n",
      "69.1%\n",
      "74.3%\n",
      "GAIA Benchmark\n",
      "Alita manus.ai OpenAI DeepResearch\n",
      "Figure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\n",
      "ABSTRACT\n",
      "Recent advances in large language models (LLMs) have enabled agents to autonomously perform\n",
      "complex, open-ended tasks. However, many existing frameworks depend heavily on manually\n",
      "predefined tools and workflows, which hinder their adaptability, scalability, and generalization\n",
      "across domains. In this work, we introduce Alita—a generalist agent designed with the principle\n",
      "of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal\n",
      "predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one\n",
      "component for direct problem-solving, making it much simpler and neater than previous approaches\n",
      "that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances\n",
      "its potential to generalize to challenging questions, without being limited by tools. For Maximal\n",
      "self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components\n",
      "to autonomously construct, refine, and reuse external capabilities by generating task-related model\n",
      "context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably,\n",
      "Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-\n",
      "purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively,\n",
      "on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More\n",
      "details will be updated at https://github.com/CharlesQ9/Alita.\n",
      "∗ These authors contributed equally to this work.\n",
      "\n",
      "1 Introduction\n",
      "\"Simplicity is the ultimate sophistication.\" — Leonardo da Vinci\n",
      "Large language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of\n",
      "independently planning and executing complex tasks on behalf of users with limited human oversight [ 2]. These\n",
      "capabilities have enabled a wide range of applications, ranging from travel planning [ 3], computer use [ 4, 5, 6],\n",
      "to the multi-step research tasks [ 7]. To support such diverse and demanding tasks, a new class of systems called\n",
      "generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified\n",
      "architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\n",
      "However, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously\n",
      "designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several\n",
      "critical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of\n",
      "real-world tasks an agent might encounter (imcomplete coverage); ii) Many complex tasks require agents to creatively\n",
      "compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components\n",
      "constrain this compositional flexibility and inhibit the development of adaptive behaviors ( limited creativity and\n",
      "flexibility); iii) It is not always the case that the interface or environment of different tools are compatible with the agent\n",
      "(mismatch). For example, many useful tools are not written in Python, which makes it difficult, though not entirely\n",
      "impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python.\n",
      "Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\n",
      "In contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two\n",
      "principles: i) Minimal Predefinition: Equip the agent with only a minimal set of core capabilities, avoiding manually\n",
      "engineered components for specific tasks or modalities; ii)Maximal Self-Evolution: Empower the agent to autonomously\n",
      "create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built\n",
      "with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed\n",
      "capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) 1 which is an open\n",
      "protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate,\n",
      "adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from\n",
      "manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple\n",
      "yet profoundly capable.\n",
      "Youtube \n",
      "Caption \n",
      "Crawler\n",
      "Image \n",
      "CaptionerUrl Text \n",
      "Extractor\n",
      "Path \n",
      "Generalist \n",
      "Classifier\n",
      "Relevant \n",
      "Patch \n",
      "Zoomer\n",
      "Web Agent MCP Box\n",
      "Alita\n",
      "(Ours)\n",
      "Minimal Predefinition\n",
      "Maximal Self-Evolution\n",
      "Self Evolving\n",
      "Other\n",
      "Agents\n",
      " \n",
      "Manager Agent\n",
      "Manager Agent\n",
      "MCP Creation\n",
      "Large-scale Manual \n",
      "Engineering\n",
      "Traditional \n",
      "Generalist\n",
      "Agents\n",
      "Scalable Dynamic Capability\n",
      "Enhanced Creativity & Flexibility\n",
      "Cross-ecosystem Compatibility\n",
      "Incomplete Coverage\n",
      "Limited Creativity & Flexibility\n",
      "Mismatch\n",
      "Web \n",
      "Agent\n",
      "Figure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on\n",
      "large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\n",
      "We conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially\n",
      "on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent\n",
      "behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions\n",
      "can be summarized as follows.\n",
      "• We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging\n",
      "conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent\n",
      "framework.\n",
      "1https://www.anthropic.com/news/model-context-protocol\n",
      "2\n",
      "\n",
      "• We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\n",
      "• We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific\n",
      "tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark.\n",
      "We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI’s Deep Research with 67.36% pass@1\n",
      "and ranking top among all general-purpose agents.\n",
      "2 Related Works\n",
      "2.1 Generalist Agent\n",
      "The concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety\n",
      "of complex tasks in a real-world environment. OWL [ 8] introduces a method that decomposes complex tasks into\n",
      "subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [ 11] proposes a multi-\n",
      "agent collaborative development framework, where each agent possesses an independent system structure, enabling\n",
      "autonomous learning and the storage of a comprehensive world model to build an independent understanding of the\n",
      "environment. OpenAI Deep Research 2 employs reinforcement learning for training on real-world tasks, aiming to\n",
      "provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable,\n",
      "modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI\n",
      "agents. The Magentic-One [ 13] framework merges the Magentic and Autogen systems, distinguishing between the\n",
      "micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and\n",
      "more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined\n",
      "tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\n",
      "2.2 Auto Generating Agent\n",
      "Auto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools,\n",
      "agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a\n",
      "distinct role, to handle the corresponding subtasks. OpenHands [ 15] offers an event-driven architecture that allows\n",
      "agents to interact with the environment like human developers, thereby enabling the creation of custom workflows.\n",
      "AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes\n",
      "invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as\n",
      "an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously.\n",
      "In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the\n",
      "completion of specific tasks, while also providing resources for future executions.\n",
      "2.3 Tool Creation\n",
      "Tool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external\n",
      "support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved\n",
      "and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated,\n",
      "extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool\n",
      "creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17]\n",
      "enables agents to autonomously create new tools based on task requirements, incorporating information gathered\n",
      "through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code\n",
      "scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison,\n",
      "Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment\n",
      "management over tool creation.\n",
      "2.4 MCP\n",
      "The Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI\n",
      "systems and external data sources and services. RAG-MCP [ 21] enhances the efficiency and accuracy of agents by\n",
      "retrieving the most relevant tools from a large collection, based on the task description, within the database composed\n",
      "of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use,\n",
      "facilitating reuse by itself and other agents.\n",
      "2https://openai.com/index/introducing-deep-research/\n",
      "3\n",
      "\n",
      "3 Methods\n",
      "We propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal\n",
      "self-evolution to tackle diverse and complex tasks. Figure 3 illustrates the framework of Alita. In contrast to generalist\n",
      "agents that typically depend on extensive manually-designed tools and workflows [8, 9], the manager agent in Alita\n",
      "solely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan\n",
      "task-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries\n",
      "and other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and\n",
      "configures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if\n",
      "any issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct,\n",
      "improving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future\n",
      "reuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a\n",
      "self-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\n",
      "Manager Agent\n",
      "Web Agent\n",
      "Open-source\n",
      "Searching\n",
      "Script \n",
      "Generating\n",
      "Virtual Env \n",
      "Execution\n",
      "CodeReAct Loop\n",
      "Output\n",
      "MCP Box\n",
      "Encapsulate\n",
      "Question\n",
      "MCP \n",
      "Brainstorming\n",
      "Self Evolving\n",
      "MCP Creation\n",
      "Figure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct\n",
      "loop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system\n",
      "dynamically performs open-source searching, script generation, and virtual environment execution to construct task-\n",
      "related functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this\n",
      "process, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously\n",
      "integrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying\n",
      "on a huge hand-crafted, elaborate tools and workflows.\n",
      "3.1 Execution Pipeline\n",
      "Each task commences with the construction of an augmented prompt that incorporates the original query. The manager\n",
      "agent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the\n",
      "agent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute\n",
      "them within isolated environments (Sec. 3.4.4).\n",
      "Upon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP\n",
      "and stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are\n",
      "systematically logged to facilitate comprehensive analysis.\n",
      "3.2 Manager Agent\n",
      "The Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the\n",
      "manager agent initially calls the MCP Brainstorming to determine whether additional tools are needed and which\n",
      "specific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web\n",
      "agent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the\n",
      "information retrieved by the web agent to generate the required new tools along with their corresponding environment\n",
      "configuration instructions. After collecting all intermediate results, the manager performs final aggregation and response\n",
      "formulation.\n",
      "4\n",
      "\n",
      "Tool Usage. In contrast to traditional systems that rely on extensive predefined toolkits, the manager agent em-\n",
      "braces Alita’s minimal philosophy by employing concise but powerful toolkits, including MCP Brainstorming,\n",
      "ScriptGeneratingTool and CodeRunningTool. Specifically, MCP Brainstorming detects functional gaps, identi-\n",
      "fies necessary supplementary tools and outlines tool specifications; ScriptGeneratingTool obtains tool specification\n",
      "outlines and then generates appropriate tools tailored to the task requirements; CodeRunningTool executes generated\n",
      "code in isolated environments and caches the output for potential MCP servers generation. These tools are intelligently\n",
      "invoked in response to the task’s evolving demands, ensuring adaptive and efficient problem-solving.\n",
      "3.3 Web Agent\n",
      "The web agent retrieves relevant information from external sources when internal knowledge is insufficient. It is\n",
      "particularly effective for tasks requiring the retrieval of domain-specific code or documentation. With a lightweight,\n",
      "text-based web interface and modular navigation tools, the web agent traverses multiple websites, extract relevant\n",
      "segments, and return reasonable URLs or raw content.\n",
      "Tool Usage. The agent utilizes SimpleTextBrowser as its web interface and page-level control tools: VisitTool,\n",
      "PageUpTool, and PageDownTool to navigate webpages. For query-based lookups, it applies GoogleSearchTool for\n",
      "open web search and GithubSearchTool to identify reusable open-source tools. This design supports real-time code\n",
      "retrieval and context-aware tool planning.\n",
      "3.4 MCP Creation Component\n",
      "To enable the creativity of the agent, we design three tools collaboratively contributing to the MCP creation process.\n",
      "3.4.1 MCP Brainstorming\n",
      "Since LLMs often exhibit overconfidence in their capabilities [ 22], we introduce MCP Brainstorming to conduct\n",
      "preliminary capability assessment by providing both the task and the description of current framework. We designed spe-\n",
      "cialized prompts to facilitate accurate self-assessment of the agent’s capabilities. Moreover, whenMCP Brainstorming\n",
      "identifies insufficient capabilities of the framework to complete the task, it provides references for tool generation to\n",
      "bridge the capability gap. This provides prior guidance for subsequent tool selection and task planning required to\n",
      "accomplish given objectives.\n",
      "3.4.2 ScriptGeneratingTool\n",
      "The ScriptGeneratingTool is a code-building utility designed for constructing external tools. It receives explicit\n",
      "subtask descriptions and suggestions for code construction from the manager agent, and potentially useful GitHub links\n",
      "obtained via the web agent, which can provide information such as README.md files or code snippets from GitHub to\n",
      "guide the script generation process. Furthermore, ScriptGeneratingTool generates the environment script to create\n",
      "the required environment for the code running and the cleaning script to clean up redundant files and environments\n",
      "generated after script execution. Therefore, ScriptGeneratingTool ensures that the generated scripts are valid,\n",
      "self-contained, and executable, making them suitable for deployment in the given task, and reusable in the future.\n",
      "3.4.3 CodeRunningTool\n",
      "The CodeRunningTool validates the functionality of the generated script by executing it within an isolated environment.\n",
      "If the execution produces the expected results, the tool is registered in the system as a reusable MCP. This process also\n",
      "supports iterative refinement, allowing for error inspection and subsequent code regeneration to improve the script’s\n",
      "performance.\n",
      "3.4.4 Environment Management\n",
      "Upon retrieving or generating a candidate tool, the system activates the environment planner module. This module\n",
      "parses the relevant repository or script metadata such as README.md, requirements.txt, and shell scripts using\n",
      "the TextInspectorTool. It extracts and validates the dependencies and setup instructions to construct an isolated\n",
      "execution profile. Subsequently, a new Conda environment is created with a unique name (typically derived from the\n",
      "task ID or a hash of the repository path), and dependencies are installed using conda install or pip install.\n",
      "All runtime environments are initialized locally in parallel, obviating the need for administrative privileges or container-\n",
      "ization technologies. This approach ensures high compatibility across various tasks while preserving the portability\n",
      "5\n",
      "\n",
      "of the system. During execution, the environment is explicitly activated prior to invoking the code interpreter, thus\n",
      "ensuring both isolation and reproducibility.\n",
      "In the event of a failure during environment initialization—due to issues such as missing packages, syntax errors in setup\n",
      "scripts, or unavailable dependencies—Alita activates an automated recovery procedure. This procedure attempts various\n",
      "fallback strategies, including relaxing version constraints or identifying the minimal set of dependencies required for\n",
      "functionality. If these recovery attempts are unsuccessful, the tool is discarded, and the failure is logged for offline\n",
      "analysis and future investigation. This enables Alita to self-correct its designed tools, thereby generating more accurate\n",
      "and robust solutions.\n",
      "4 Experiments\n",
      "4.1 Experiment Setting\n",
      "4.1.1 Benchmarks\n",
      "To evaluate the general task-handling capabilities of Alita, we conducted extensive testing across multiple agent\n",
      "benchmarks.\n",
      "GAIA [10]: GAIA is a benchmark designed to assess the capabilities of general-purpose AI assistants. It consists of\n",
      "466 real-world scenario-based questions covering daily tasks, scientific reasoning, web browsing, and tool usage. While\n",
      "these tasks are conceptually simple for humans, they are challenging for most advanced AI systems.\n",
      "Mathvista [23]: MathVista is a comprehensive benchmark designed to evaluate the mathematical reasoning capabilities\n",
      "of foundation models within visual contexts. It can effectively evaluate the model’s capabilities in visual comprehension,\n",
      "mathematical reasoning, programming, and other related skills. Due to limitations in resources, we randomly selected\n",
      "100 samples from the dataset.\n",
      "Pathvqa [24]: PathVQA is a medical visual question answering dataset. It can effectively assess the agent’s capabilities\n",
      "across multiple dimensions, including visual understanding, spatial Reasoning, medical Knowledge search or integration,\n",
      "and natural language processing. Due to limitations in resources, we randomly selected 100 samples from the dataset.\n",
      "4.1.2 Baselines\n",
      "We include a variety of baselines for comparison. For the GAIA benchmark, there are more baselines available on the\n",
      "GAIA leaderboard3.\n",
      "Octotools [9]: OctoTools is a recent framework designed to streamline multi-tool workflows in complex computational\n",
      "tasks. With over 10 standardized tool cards encapsulating various functionalities, the agent gains powerful capabilities\n",
      "to handle multi-domain tasks.\n",
      "Open Deep Research-smolagents4 [25]: Open Deep Research is an open-source agent developed under Hugging\n",
      "Face’s Smolagents project, designed to automate complex multi-step research tasks. Alita’s development is largely\n",
      "based on the framework of Open Deep Research-smolagents. However, we remove many pre-defined tools and also add\n",
      "the MCP creation component to follow the design principle of minimal predefinition and maximal self-evolution.\n",
      "AutoAgent [17]: AutoAgent is a zero-code platform designed to facilitate the creation, customization, and deployment\n",
      "of agents powered by LLMs. By providing a natural language interface, it allows users to develop multi-agent systems,\n",
      "design workflows, and integrate tools without requiring technical expertise.\n",
      "OWL [8]: OWL is an open-source, multi-agent framework built on the CAMEL-AI platform, designed to support the\n",
      "automation of complex real-world tasks through dynamic agent collaboration. OWL decomposes tasks into specialized\n",
      "sub-tasks, each of which is managed by a distinct agent type—such as UserAgents, AssistantAgents, and ToolAgents.\n",
      "A-World [12]: A-World is an open-source multi-agent system framework designed to simplify the construction,\n",
      "evaluation, and deployment of general multi-agent tasks. Through its modular design, the framework supports\n",
      "autonomous decision-making, tool usage, and collaboration among agents.\n",
      "OpenAI Deep Research5: OpenAI’s Deep Research is an advanced AI agent integrated with ChatGPT, designed to\n",
      "autonomously perform multi-step research tasks by synthesizing information from diverse online sources. This agentic\n",
      "3https://huggingface.co/spaces/gaia-benchmark/leaderboard\n",
      "4https://huggingface.co/blog/open-deep-research\n",
      "5https://openai.com/index/introducing-deep-research/\n",
      "6\n",
      "\n",
      "framework excels in generating comprehensive reports on complex topics and has shown superior performance on\n",
      "benchmarks.\n",
      "4.2 Results\n",
      "We run three rounds of testing on GAIA and achieved the best performance on the GAIA leaderboard, surpassing\n",
      "other agent systems. Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and 87.27% pass@3 accuracy,\n",
      "which is top-ranking on the GAIA benchmark validation dataset, outperforming many agent systems with far greater\n",
      "complexity. Alita with Claude 3.7 Sonnet + GPT-4o achieves 72.73% pass@1 and 86.06% pass@3 on GAIA, and\n",
      "further attains 74.00% and 52.00% pass@1 on the Mathvista and PathVQA benchmarks, respectively, outperforming\n",
      "Octotools and Open Deep Research by smolagents. More detailed results are shown in Table 1.\n",
      "Agent\n",
      "GAIA Mathvista PathVQA\n",
      "level1 level2 level3 total\n",
      "Alita (Claude-3.7-Sonnet, GPT-4o) (%)\n",
      "pass@1 81.13 75.58 46.15 72.73 74 52\n",
      "pass@2 88.68 80.23 53.85 78.79 - -\n",
      "pass@3 96.23 86.04 65.38 86.06 - -\n",
      "Alita (Claude-Sonnet-4, GPT-4o) (%)\n",
      "pass@1 77.36 76.74 65.38 75.15 - -\n",
      "pass@3 88.68 89.53 76.92 87.27 - -\n",
      "Baselines (%)\n",
      "Octotools - - - 18.40 68 47\n",
      "ODR-smolagents 67.92 53.49 34.62 55.15 65 42\n",
      "AutoAgent 71.70 53.49 26.92 55.15 - -\n",
      "OWL 84.91 67.44 42.31 69.09 - -\n",
      "A-World 86.79 69.77 34.62 69.70 - -\n",
      "OpenAI-DR 74.29 69.06 47.60 67.36 - -\n",
      "Table 1: Performance comparison of Alita and baseline agent systems on the GAIA, Mathvista, and PathVQA\n",
      "benchmarks. ODR-Smolagents refers to the Open Deep Research agent in the Smolagents framework. OpenAI-DR\n",
      "refers to OpenAI’s Deep Research. The table presents the accuracy at different levels of difficulty for GAIA, as well as\n",
      "the overall performance on Mathvista and PathVQA. The pass@1, pass@2, and pass@3 denote the accuracy achieved\n",
      "by running the Alita framework 1, 2, and 3 times, respectively, and selecting the best answer. Alita outperforms all\n",
      "baseline agents across the GAIA levels, achieving the highest total accuracy.\n",
      "5 Analysis\n",
      "5.1 Reuse of Alita-Generated MCPs\n",
      "5.1.1 Overview\n",
      "We collect the MCPs generated from running the GAIA dataset using Alita in conjunction with powerful models\n",
      "(Claude-3.7-Sonnet and GPT-4o). The benefits of reusing Alita-generated MCPs are two-fold. First, these MCPs can be\n",
      "reused by other agent frameworks and improve their performance since Alita, instead of human developers, designs a\n",
      "set of useful MCPs fit to GAIA by trial and error. Second, these MCPs can be reused by agents with smaller LLMs\n",
      "and significantly improve the performance. The reuse of auto-generated MCPs for agents with smaller LLMs can be\n",
      "viewed as a new way of distillation from larger LLMs. Traditionally, distillation might be fine-tuning smaller LLMs on\n",
      "data generated by larger LLMs. In comparison, the reuse of MCPs generated from agents with larger LLMs is much\n",
      "easier, cheaper, and faster than traditional distillation.\n",
      "7\n",
      "\n",
      "5.1.2 Reuse by Open Deep Research-smolagents\n",
      "We run open Deep Research-smolagents [25] on GAIA with and without Alita-generated MCPs based on GPT-4o. The\n",
      "results are presented in Table 2. From this experiment, we observe that the reuse of Alita-generated MCPs results in\n",
      "better performance compared to the base framework for all difficulty levels. This demonstrates that Alita can generate\n",
      "very useful MCPs, which can be provided to other agents, helping them enhance their capabilities and solve problems\n",
      "that would otherwise be unsolvable. Additionally, the consistent improvement across all difficulty levels indicates that\n",
      "Alita’s MCPs provide generalizable utility rather than just addressing specific edge cases in the dataset.\n",
      "Model Configuration Level 1 Level 2 Level 3 Total\n",
      "ODR-smolagents + GPT-4o(No Alita MCPs) 33.96% 29.07% 11.54% 27.88%\n",
      "ODR-smolagents + GPT-4o(With Alita MCPs) 39.62% 36.05% 15.38% 33.94%\n",
      "Table 2: Comparison of performance between ODR-smolagents with and without Alita-generated MCPs. The results\n",
      "are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\n",
      "performance at the respective GAIA levels. The reuse of Alita-generated MCPs can enhance the performance of other\n",
      "agents.\n",
      "5.1.3 Reuse by Base Agent on Smaller LLM\n",
      "We reuse MCPs in the base framework, i.e., ODR-smolagents [25], without the MCP creation component in Alita, and\n",
      "also with some extra pre-defined tools used in ODR-smolagents based on GPT-4o-mini. The results are presented in\n",
      "Table 3.\n",
      "Model Configuration Level 1 Level 2 Level 3 Average\n",
      "Base Framework + GPT-4o-mini (No Alita MCP) 32.08% 20.93% 3.85% 21.82%\n",
      "Base Framework + GPT-4o-mini (With Alita MCP) 39.62% 27.91% 11.54% 29.09%\n",
      "Table 3: Comparison of performance between the base framework on GPT-4o-mini, with and without Alita-generated\n",
      "MCPs. The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column\n",
      "corresponds to the performance at the respective GAIA levels. The reuse of Alita-generated MCPs significantly\n",
      "enhances the performance of agents on smaller LLMs.\n",
      "From this experiment, we observe that the reuse of Alita-generated MCPs significantly improves performance over the\n",
      "base framework based on a smaller LLM. This is because the Alita-generated MCPs can be considered MCPs distilled\n",
      "from powerful models (Claude-3.7-Sonnet), which are made available for agents on smaller LLMs. This helps bridge\n",
      "the gap between the agents on smaller LLMs and agents on larger LLMs in certain domains, thereby enhancing its\n",
      "task-processing capabilities. Especially for Level 3, we observe a particularly dramatic improvement with the accuracy\n",
      "tripling from 3.85% to 11.54%. This substantial improvement on the most challenging problems demonstrates that\n",
      "Alita-generated MCPs are especially valuable for complex reasoning tasks where agents on smaller LLMs typically\n",
      "struggle the most. The MCPs effectively encapsulate sophisticated problem-solving capabilities that the smaller model\n",
      "can leverage without needing to develop the full reasoning chain independently.\n",
      "5.2 Alita on Smaller LLM\n",
      "We hypothesize that Alita will be even stronger with the increasing coding and reasoning capabilities of LLMs in\n",
      "the future. To validate our performance, we run Alita on GAIA using GPT-4o-mini instead of Claude-3.7-Sonnet. The\n",
      "results can be found in Table 4. Different to the experiment in Section 5.1.3, the agent doesn’t have distilled MCPs - the\n",
      "agent on GPT-4o-mini model must generate its own MCPs. The results are presented in Table 4.\n",
      "From this experiment, on one hand, we observe that Alita, after replacing the models with GPT-4o-mini, performs\n",
      "significantly worse on GAIA. This substantial performance gap highlights the critical role of the underlying models’\n",
      "coding capabilities. On the other hand, the performance of Alita increases rapidly as the capabilities of the underlying\n",
      "models improve. We can expect that with future updates to the LLMs, Alita’s performance will continue to strengthen,\n",
      "surpassing its current capabilities. The design of future generalist agents might be much simpler in the future, without\n",
      "any predefined tools and workflows for direct problem-solving. Instead, human developers might focus on designing\n",
      "modules for enabling and stimulating the creativity and evolution of generalist agents.\n",
      "8\n",
      "\n",
      "Model Configuration Level 1 Level 2 Level 3 Total\n",
      "Alita (Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% 72.73%\n",
      "Alita (GPT-4o-mini) 54.72% 44.19% 19.23% 43.64%\n",
      "Table 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results\n",
      "are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\n",
      "performance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\n",
      "5.3 Case Study\n",
      "To investigate Alita’s workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3\n",
      "difficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe\n",
      "that Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying\n",
      "and utilizing relevant resources to implement a feasible MCP that aids in completing the task.\n",
      "6 Conclusion\n",
      "In this work, we introduced Alita, a generalist agent designed with the principles of minimal predefinition and maximal\n",
      "self-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving,\n",
      "Alita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach\n",
      "demonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of\n",
      "generalist agents.\n",
      "9\n",
      "\n",
      "References\n",
      "[1] OpenAI. Introducing deep research.\n",
      "[2] Noam Kolt. Governing ai agents. arXiv preprint arXiv:2501.07913, 2025.\n",
      "[3] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su.\n",
      "Travelplanner: A benchmark for real-world planning with language agents. arXiv preprint arXiv:2402.01622,\n",
      "2024.\n",
      "[4] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua, Zhoujun\n",
      "Cheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents for open-ended tasks in\n",
      "real computer environments. Advances in Neural Information Processing Systems, 37:52040–52094, 2024.\n",
      "[5] Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, and Kam-Fai Wong.\n",
      "AppBench: Planning of multiple APIs from various APPs for complex user instruction. In Yaser Al-Onaizan,\n",
      "Mohit Bansal, and Yun-Nung Chen, editors,Proceedings of the 2024 Conference on Empirical Methods in Natural\n",
      "Language Processing, pages 15322–15336, Miami, Florida, USA, November 2024. Association for Computational\n",
      "Linguistics.\n",
      "[6] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin\n",
      "Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli\n",
      "Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao\n",
      "Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, and Guang Shi. Ui-tars:\n",
      "Pioneering automated gui interaction with native agents, 2025.\n",
      "[7] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research.\n",
      "arXiv preprint arXiv:2502.04644, 2025.\n",
      "[8] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru\n",
      "Li, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for\n",
      "general multi-agent assistance in real-world task automation, 2025.\n",
      "[9] Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, and James Zou. Octotools: An agentic framework\n",
      "with extensible tools for complex reasoning. arXiv preprint arXiv:2502.11271, 2025.\n",
      "[10] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for\n",
      "general ai assistants. In The Twelfth International Conference on Learning Representations, 2023.\n",
      "[11] Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize\n",
      "Chen, et al. Long term memory: The foundation of ai self-evolution. arXiv preprint arXiv:2410.15665, 2024.\n",
      "[12] Agent Team at Ant Group. Aworld: A unified agent playground for computer and phone use tasks, 2025.\n",
      "[13] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner,\n",
      "Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor\n",
      "Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, and Saleema Amershi. Magentic-one: A generalist multi-agent\n",
      "system for solving complex tasks, 2024.\n",
      "[14] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F Karlsson, Jie Fu, and Yemin Shi.\n",
      "Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:2309.17288, 2023.\n",
      "[15] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song,\n",
      "Bowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. In\n",
      "The Thirteenth International Conference on Learning Representations, 2024.\n",
      "[16] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng,\n",
      "Sirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762,\n",
      "2024.\n",
      "[17] Jiabin Tang, Tianyu Fan, and Chao Huang. Autoagent: A fully-automated and zero-code framework for llm agents.\n",
      "arXiv e-prints, pages arXiv–2502, 2025.\n",
      "[18] Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, and Heng Ji. Craft: Customizing llms by creating\n",
      "and retrieving from specialized toolsets. arXiv preprint arXiv:2309.17428, 2023.\n",
      "[19] Zhiruo Wang, Daniel Fried, and Graham Neubig. Trove: Inducing verifiable and efficient toolboxes for solving\n",
      "programmatic tasks. arXiv preprint arXiv:2401.12869, 2024.\n",
      "[20] Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. Creator: Tool creation for disentangling\n",
      "abstract and concrete reasoning of large language models. arXiv preprint arXiv:2305.14318, 2023.\n",
      "10\n",
      "\n",
      "[21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented\n",
      "generation. arXiv preprint arXiv:2505.03275, 2025.\n",
      "[22] Fengfei Sun, Ningke Li, Kailong Wang, and Lorenz Goette. Large language models are overconfident and amplify\n",
      "human bias. 2025.\n",
      "[23] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang,\n",
      "Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual\n",
      "contexts. In International Conference on Learning Representations (ICLR), 2024.\n",
      "[24] Xuehai He, Yichen Zhang, Luntian Mou, Eric P. Xing, and Pengtao Xie. Pathvqa: 30000+ questions for medical\n",
      "visual question answering. ArXiv, abs/2003.10286, 2020.\n",
      "[25] Aymeric Roucher, Albert Villanova del Moral, Thomas Wolf, Leandro von Werra, and Erik Kaunismäki. ‘smo-\n",
      "lagents‘: a smol library to build great agentic systems. https://github.com/huggingface/smolagents,\n",
      "2025.\n",
      "11\n",
      "\n",
      "A Detailed Case Study\n",
      "Case Study: YouTube 360 VR Video Subtitle Extraction\n",
      "Question ID: 0512426f-4d28-49f0-be77-06d05daec096\n",
      "Question: In the YouTube 360 VR video from March 2018 narrated by the voice actor of Lord of the Rings’\n",
      "Gollum, what number was mentioned by the narrator directly after dinosaurs were first shown in the video?\n",
      "Our Answer: 100000000\n",
      "Correct Answer: 100000000\n",
      "Is Correct: Yes\n",
      "Generated MCP: YouTube Video Subtitle Crawler\n",
      "Alita Workflow:\n",
      "1. MCP Brainstorming: Alita propose the development of a \"YouTube Video Subtitle Crawler\" MCP, which\n",
      "should automate the extraction of subtitles from a given YouTube video. This involves scraping the subtitles of\n",
      "the video and processing them to isolate the relevant text after the event in question.\n",
      "2. Web Agent Execution: To implement the subtitle extraction, a search is conducted in open-source\n",
      "repositories to find relevant tools that can assist in extracting YouTube video transcripts. An appropriate tool,\n",
      "the youtube-transcript-api, is identified from the following GitHub repository:\n",
      "https://github.com/jdepoix/youtube-transcript-api\n",
      "3. Manager Agent: The Manager Agent synthesizes the information from the GitHub repository and proceeds\n",
      "to write a Python function that leverages the youtube-transcript-api to retrieve the transcript of the video with\n",
      "corresponding environment setup instructions.\n",
      "The environment setup and installation steps are defined as follows:\n",
      "conda create -n youtube_transcript\n",
      "conda activate youtube_transcript\n",
      "pip install youtube-transcript-api\n",
      "The Python code to retrieve the video transcript is as follows:\n",
      "from youtube_transcript_api import YouTubeTranscriptApi\n",
      "# Initialize the API\n",
      "ytt_api = YouTubeTranscriptApi()\n",
      "# Retrieve the transcript\n",
      "video_id = ...\n",
      "transcript_list = ytt_api.list(’video_id’)\n",
      "...\n",
      "4. Manager Agent Execution: Leveraging the Python code and the established environment, the Manager\n",
      "Agent successfully packaged the YouTube Video Subtitle Crawler MCP. Subsequently, this MCP was employed\n",
      "to efficiently scrape the subtitles from the video, enabling the extraction of the relevant content. After analyzing\n",
      "the content, the correct number (100000000) mentioned by the narrator following the dinosaur scene is extracted\n",
      "from the transcript.\n",
      "5. Final Output: The number \"100000000\" is identified as the correct answer.\n",
      "B Limitations\n",
      "Alita highly relies on the coding capability of LLM. When the LLM’s coding capability is really poor, our method will\n",
      "perform worse than traditional generalist agent.\n",
      "12\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## summary ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The case study demonstrates Alita’s workflow for extracting a specific piece of information from a YouTube 360 VR video. The process begins with an MCP Brainstorming step, where Alita identifies the need for a “YouTube Video Subtitle Crawler” MCP to automate subtitle extraction. The Web Agent then searches open‑source repositories and locates the `youtube-transcript-api` library on GitHub. The Manager Agent synthesizes this information, writes a Python function that uses the API to fetch the transcript, and generates environment setup instructions (conda environment creation and pip install). Once the code is executed in the prepared environment, the Manager Agent packages the function into the MCP, which is then used to scrape the subtitles from the target video. By parsing the transcript, Alita identifies the number “100000000” mentioned immediately after the dinosaurs are first shown. This answer matches the correct answer provided in the dataset.\n",
      "\n",
      "[[ ## summary ## ]]\n",
      "Alita successfully generated a YouTube Video Subtitle Crawler MCP, executed it to retrieve the transcript of the specified 360 VR video, and extracted the correct number “100000000” mentioned by the narrator after the dinosaur scene. The workflow involved MCP brainstorming, web search for an open‑source tool, environment setup, code generation, MCP packaging, and final answer extraction.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6aa49",
   "metadata": {},
   "source": [
    "## DSPy predict - A zero vector DB example\n",
    "\n",
    "Adding an instruction to the Signature helps us to couch the LLM's reply.\n",
    "\n",
    "> Not recommended because the document will greatly clog the LLM's context window. This code just demonstrates the power of having a long context window and how to use DSPy declarative signatures with instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac9feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector_db = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "        'document: str, question: str -> answer: str',\n",
    "        instructions='Only use the document to answer the question and nothing else.'\n",
    "    )\n",
    ")\n",
    "\n",
    "question = 'How does ALITA help LLMs to achieve autonomous reasoning?'\n",
    "response = zero_vector_db(question=question, document=doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8362814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ALITA enables large language models (LLMs) to perform autonomous reasoning by adopting a design philosophy of **minimal predefinition and maximal self‑evolution**.  \n",
       "Key mechanisms include:\n",
       "\n",
       "1. **MCP Brainstorming** – The LLM first introspects the task, identifies missing capabilities, and proposes new *Model‑agnostic Toolchains* (MCPs) that can be built on‑the‑fly.  \n",
       "2. **Web Agent Retrieval** – It searches public code repositories and APIs to find existing libraries that can implement the proposed MCP, thereby avoiding the need for the model to write code from scratch.  \n",
       "3. **Dynamic Environment Construction** – The LLM generates the necessary environment‑setup commands (e.g., conda or pip installs) and integrates them with the retrieved code.  \n",
       "4. **Self‑Generated MCP Packaging** – The model packages the retrieved code and environment instructions into a reusable MCP, which can be invoked as a tool for the current task.  \n",
       "5. **Iterative Refinement** – If the first attempt fails, the model can regenerate the MCP or adjust its reasoning chain, effectively learning from its own failures.  \n",
       "\n",
       "By allowing the model to **create, evolve, and reuse tools in real time**, ALITA turns the LLM into an autonomous reasoner that no longer relies on a fixed set of pre‑built tools or workflows. This self‑evolving capability scales with the underlying model’s coding and reasoning power, enabling more complex, multi‑step problem solving without human‑written tool libraries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428d0bd",
   "metadata": {},
   "source": [
    "YES!! No vector database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18cc75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-12T22:02:07.095044]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `document` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## document ## ]]\n",
      "{document}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Only use the document to answer the question and nothing else.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## document ## ]]\n",
      "arXiv:2505.20286v1  [cs.AI]  26 May 2025\n",
      "ALITA : G ENERALIST AGENT ENABLING SCALABLE AGENTIC\n",
      "REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL\n",
      "SELF -EVOLUTION\n",
      "Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin Yao1,\n",
      "Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1, Yue Wu1, Kaixuan Huang1, Shilong Liu1,\n",
      "Hongru Wang6, Mengdi Wang1\n",
      "1AI Lab, Princeton University 2IIIS, Tsinghua University 3Shanghai Jiao Tong University\n",
      "4University of Michigan 5Tianqiao and Chrissy Chen Institute 6The Chinese University of Hong Kong\n",
      "0.3 0.4 0.5 0.6 0.7 0.8 0.9\n",
      "Average\n",
      "Level 3\n",
      "Level 2\n",
      "Level 1\n",
      "87.3%\n",
      "76.9%\n",
      "89.5%\n",
      "88.7%\n",
      "73.3%\n",
      "57.7%\n",
      "70.1%\n",
      "86.5%\n",
      "67.4%\n",
      "47.6%\n",
      "69.1%\n",
      "74.3%\n",
      "GAIA Benchmark\n",
      "Alita manus.ai OpenAI DeepResearch\n",
      "Figure 1: Performance of Alita, manus.ai, and OpenAI DeepResearch[1]\n",
      "ABSTRACT\n",
      "Recent advances in large language models (LLMs) have enabled agents to autonomously perform\n",
      "complex, open-ended tasks. However, many existing frameworks depend heavily on manually\n",
      "predefined tools and workflows, which hinder their adaptability, scalability, and generalization\n",
      "across domains. In this work, we introduce Alita—a generalist agent designed with the principle\n",
      "of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal\n",
      "predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one\n",
      "component for direct problem-solving, making it much simpler and neater than previous approaches\n",
      "that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances\n",
      "its potential to generalize to challenging questions, without being limited by tools. For Maximal\n",
      "self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components\n",
      "to autonomously construct, refine, and reuse external capabilities by generating task-related model\n",
      "context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably,\n",
      "Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-\n",
      "purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively,\n",
      "on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More\n",
      "details will be updated at https://github.com/CharlesQ9/Alita.\n",
      "∗ These authors contributed equally to this work.\n",
      "\n",
      "1 Introduction\n",
      "\"Simplicity is the ultimate sophistication.\" — Leonardo da Vinci\n",
      "Large language models (LLMs) have rapidly evolved from merely generating text to autonomous agents capable of\n",
      "independently planning and executing complex tasks on behalf of users with limited human oversight [ 2]. These\n",
      "capabilities have enabled a wide range of applications, ranging from travel planning [ 3], computer use [ 4, 5, 6],\n",
      "to the multi-step research tasks [ 7]. To support such diverse and demanding tasks, a new class of systems called\n",
      "generalist agents has emerged. These agents are designed to handle a wide range of domains and tasks through a unified\n",
      "architecture, allowing them to generalize beyond task-specific solutions, such as OpenAI Deep Research [1] and Manus.\n",
      "However, most of the current general-purpose agents heavily rely on large-scale manual engineering, including tediously\n",
      "designed workflows, considerable pre-defined tools, and hardcoded components [8, 9]. This reliance introduces several\n",
      "critical limitations: i) It is impractical, if not impossible, to predefine all the tools required for the wide variety of\n",
      "real-world tasks an agent might encounter (imcomplete coverage); ii) Many complex tasks require agents to creatively\n",
      "compose new tools or leverage existing ones in novel ways while pre-designed workflow and hardcoded components\n",
      "constrain this compositional flexibility and inhibit the development of adaptive behaviors ( limited creativity and\n",
      "flexibility); iii) It is not always the case that the interface or environment of different tools are compatible with the agent\n",
      "(mismatch). For example, many useful tools are not written in Python, which makes it difficult, though not entirely\n",
      "impossible, for them to be pre-connected to the mainstream agent frameworks that are primarily written in Python.\n",
      "Together, these challenges ultimately hinder the scalability, adaptability, and generalization of existing generalist agents.\n",
      "In contrast to the prevailing trend of growing complexity, we propose a radically simple design philosophy built on two\n",
      "principles: i) Minimal Predefinition: Equip the agent with only a minimal set of core capabilities, avoiding manually\n",
      "engineered components for specific tasks or modalities; ii)Maximal Self-Evolution: Empower the agent to autonomously\n",
      "create, refine, and reuse external capabilities as needed. We instantiate this vision through Alita, a generalist agent built\n",
      "with a single core capability (i.e., the web agent) and a small set of general-purpose modules that enable self-directed\n",
      "capability expansion. Specifically, we take advantage of the Model Context Protocols (MCPs) 1 which is an open\n",
      "protocol that standardizes how different systems provide context to LLMs, and empower Alita to dynamically generate,\n",
      "adapt, and reuse MCPs based on the demands of each task rather than relying on static, predefined tools. This shift from\n",
      "manually designed capabilities to on-the-fly MCP construction unlocks a new path for building agents that are simple\n",
      "yet profoundly capable.\n",
      "Youtube \n",
      "Caption \n",
      "Crawler\n",
      "Image \n",
      "CaptionerUrl Text \n",
      "Extractor\n",
      "Path \n",
      "Generalist \n",
      "Classifier\n",
      "Relevant \n",
      "Patch \n",
      "Zoomer\n",
      "Web Agent MCP Box\n",
      "Alita\n",
      "(Ours)\n",
      "Minimal Predefinition\n",
      "Maximal Self-Evolution\n",
      "Self Evolving\n",
      "Other\n",
      "Agents\n",
      " \n",
      "Manager Agent\n",
      "Manager Agent\n",
      "MCP Creation\n",
      "Large-scale Manual \n",
      "Engineering\n",
      "Traditional \n",
      "Generalist\n",
      "Agents\n",
      "Scalable Dynamic Capability\n",
      "Enhanced Creativity & Flexibility\n",
      "Cross-ecosystem Compatibility\n",
      "Incomplete Coverage\n",
      "Limited Creativity & Flexibility\n",
      "Mismatch\n",
      "Web \n",
      "Agent\n",
      "Figure 2: Comparison between Traditional Generalist Agents and Alita. Traditional generalist agents heavily rely on\n",
      "large-scale manual engineering while Alita adheres to minimal predefinition and maximal self-evolution.\n",
      "We conduct comprehensive experiments on several benchmarks to assess Alita in real-world applications, especially\n",
      "on the most popular GAIA [10]. Alita proves that simplicity is not a constraint, but a strength, and that creative agent\n",
      "behavior can emerge from a design that prioritizes autonomy over manual engineering. To sum up, our key contributions\n",
      "can be summarized as follows.\n",
      "• We propose a new agent architecture centered on minimal predefinition and maximal self-evolution, challenging\n",
      "conventional design norms in generalist agents, aiming to call for a more scalable and generalizable agent\n",
      "framework.\n",
      "1https://www.anthropic.com/news/model-context-protocol\n",
      "2\n",
      "\n",
      "• We present Alita, a generalist agent that achieves scalable agentic reasoning with a radically simple design.\n",
      "• We empirically demonstrate that Alita, despite using no complex predefined tools and workflows for specific\n",
      "tasks, outperforms many systems with significantly more handcrafted complexity on the GAIA benchmark.\n",
      "We achieve 75.15% pass@1 and 87.27% pass@3, surpassing OpenAI’s Deep Research with 67.36% pass@1\n",
      "and ranking top among all general-purpose agents.\n",
      "2 Related Works\n",
      "2.1 Generalist Agent\n",
      "The concept of a Generalist Agent aims to construct an AI agent system capable of collaboratively completing a variety\n",
      "of complex tasks in a real-world environment. OWL [ 8] introduces a method that decomposes complex tasks into\n",
      "subtasks and dynamically allocates them to worker nodes with specialized toolkits. Omne [ 11] proposes a multi-\n",
      "agent collaborative development framework, where each agent possesses an independent system structure, enabling\n",
      "autonomous learning and the storage of a comprehensive world model to build an independent understanding of the\n",
      "environment. OpenAI Deep Research 2 employs reinforcement learning for training on real-world tasks, aiming to\n",
      "provide precise and reliable research reports for knowledge-intensive tasks. A-World [12] offers a highly configurable,\n",
      "modular, and scalable simulation environment, allowing developers to flexibly define and integrate different types of AI\n",
      "agents. The Magentic-One [ 13] framework merges the Magentic and Autogen systems, distinguishing between the\n",
      "micro-level LLM-driven function generation and the macro-level multi-agent orchestration, resulting in a clearer and\n",
      "more efficient construction of agent systems. Alita, also a Generalist Agent, allows for the minimal use of predefined\n",
      "tools and workflows for direct problem-solving, yet still achieves impressive performance across diverse tasks.\n",
      "2.2 Auto Generating Agent\n",
      "Auto-generating agents aim to enhance the versatility of agents by enabling them to autonomously generate tools,\n",
      "agents, or workflows tailored to specific tasks. AutoAgents [14], for instance, generate multiple agents, each playing a\n",
      "distinct role, to handle the corresponding subtasks. OpenHands [ 15] offers an event-driven architecture that allows\n",
      "agents to interact with the environment like human developers, thereby enabling the creation of custom workflows.\n",
      "AFlow [16] redefines workflow optimization as a search problem, where each workflow consists of several nodes\n",
      "invoking large LLMs, and the optimal workflow is identified and executed through a search process. AutoAgent [17], as\n",
      "an autonomous agent operating system, permits agents to manage system-level operations and file data autonomously.\n",
      "In Alita, agents are empowered to automatically generate diverse, specialized, and highly accurate MCPs to aid in the\n",
      "completion of specific tasks, while also providing resources for future executions.\n",
      "2.3 Tool Creation\n",
      "Tool Creation enables agents to autonomously create tools to assist in task execution, either on their own or with external\n",
      "support. CRAFT [18] utilizes GPT-4 to generate a set of code snippets that function as tools, which are then retrieved\n",
      "and used in the system. TroVE [19] maintains a collection of high-level functions, which are automatically generated,\n",
      "extended, and periodically pruned to optimize program generation. CREATOR [20] decouples the abstraction of tool\n",
      "creation from the actual execution, allowing LLMs to address tasks at different levels of granularity. AutoAgent [17]\n",
      "enables agents to autonomously create new tools based on task requirements, incorporating information gathered\n",
      "through web searches and integrating these tools into their workflow. OpenHands [15] allows agents to create code\n",
      "scripts in a human-like manner during interaction with the environment to assist in task completion. In comparison,\n",
      "Alita enables MCP creation, which provides additional benefits, including better reusability and easy environment\n",
      "management over tool creation.\n",
      "2.4 MCP\n",
      "The Model Context Protocol (MCP) is a standard proposed by Anthropic, designed to unify the connection between AI\n",
      "systems and external data sources and services. RAG-MCP [ 21] enhances the efficiency and accuracy of agents by\n",
      "retrieving the most relevant tools from a large collection, based on the task description, within the database composed\n",
      "of MCP descriptions. After tool generation, Alita wraps the generated valid tools into MCPs for subsequent use,\n",
      "facilitating reuse by itself and other agents.\n",
      "2https://openai.com/index/introducing-deep-research/\n",
      "3\n",
      "\n",
      "3 Methods\n",
      "We propose Alita, a generalist agent enabling scalable agentic reasoning with minimal predefinition and maximal\n",
      "self-evolution to tackle diverse and complex tasks. Figure 3 illustrates the framework of Alita. In contrast to generalist\n",
      "agents that typically depend on extensive manually-designed tools and workflows [8, 9], the manager agent in Alita\n",
      "solely orchestrates the web agent using only basic tools. Through this approach, our framework enables Alita to plan\n",
      "task-specific tools through brainstorming. It then utilizes a Web Agent to search for helpful open-source libraries\n",
      "and other resources related to these tools. Leveraging the search results, Alita autonomously generates new tools and\n",
      "configures the necessary environments to enhance its capabilities and effectively solve tasks. During this process, if\n",
      "any issues arise with the newly generated tools or their environments, Alita can provide feedback and self-correct,\n",
      "improving the quality of the generated tools. Furthermore, the new tools can be encapsulated as MCP servers for future\n",
      "reuse. With the aid of MCPs, Alita can generate increasingly powerful, diverse, and complex MCPs, thus establishing a\n",
      "self-reinforcing cycle. Therefore, Alita autonomously expands its capabilities through continuous MCP integration.\n",
      "Manager Agent\n",
      "Web Agent\n",
      "Open-source\n",
      "Searching\n",
      "Script \n",
      "Generating\n",
      "Virtual Env \n",
      "Execution\n",
      "CodeReAct Loop\n",
      "Output\n",
      "MCP Box\n",
      "Encapsulate\n",
      "Question\n",
      "MCP \n",
      "Brainstorming\n",
      "Self Evolving\n",
      "MCP Creation\n",
      "Figure 3: The architecture of Alita. Upon receiving a question, the Manager Agent initiates an iterative CodeReAct\n",
      "loop to analyze tasks, identify functional gaps, and trigger MCP Brainstorming for creative synthesis. The system\n",
      "dynamically performs open-source searching, script generation, and virtual environment execution to construct task-\n",
      "related functions. Useful ones are encapsulated into reusable MCPs and stored in the MCP Box. Throughout this\n",
      "process, the Manager Agent collaborates with the Web Agent for external information retrieval and continuously\n",
      "integrates intermediate results until a final output is produced. This process enables Alita to self-evolve without relying\n",
      "on a huge hand-crafted, elaborate tools and workflows.\n",
      "3.1 Execution Pipeline\n",
      "Each task commences with the construction of an augmented prompt that incorporates the original query. The manager\n",
      "agent (Sec. 3.2) then initiates a multi-step reasoning process to address the task at hand. Throughout this process, the\n",
      "agent may query external sources via the web agent (Sec. 3.3), plan and synthesize new tools (Sec. 3.4), and execute\n",
      "them within isolated environments (Sec. 3.4.4).\n",
      "Upon successful tool generation and accurate result formulation, the corresponding script is transformed into an MCP\n",
      "and stored in the internal tool registry for future reuse. All reasoning steps, intermediate code, and final outputs are\n",
      "systematically logged to facilitate comprehensive analysis.\n",
      "3.2 Manager Agent\n",
      "The Manager Agent functions as the central coordinator within framework of Alita. When receiving a task prompt, the\n",
      "manager agent initially calls the MCP Brainstorming to determine whether additional tools are needed and which\n",
      "specific tools are required. Then the manager agent decomposes the task into subtasks and dispatches them to web\n",
      "agent or generates the required external tools to complete the subtask. When necessary, the manager agent utilizes the\n",
      "information retrieved by the web agent to generate the required new tools along with their corresponding environment\n",
      "configuration instructions. After collecting all intermediate results, the manager performs final aggregation and response\n",
      "formulation.\n",
      "4\n",
      "\n",
      "Tool Usage. In contrast to traditional systems that rely on extensive predefined toolkits, the manager agent em-\n",
      "braces Alita’s minimal philosophy by employing concise but powerful toolkits, including MCP Brainstorming,\n",
      "ScriptGeneratingTool and CodeRunningTool. Specifically, MCP Brainstorming detects functional gaps, identi-\n",
      "fies necessary supplementary tools and outlines tool specifications; ScriptGeneratingTool obtains tool specification\n",
      "outlines and then generates appropriate tools tailored to the task requirements; CodeRunningTool executes generated\n",
      "code in isolated environments and caches the output for potential MCP servers generation. These tools are intelligently\n",
      "invoked in response to the task’s evolving demands, ensuring adaptive and efficient problem-solving.\n",
      "3.3 Web Agent\n",
      "The web agent retrieves relevant information from external sources when internal knowledge is insufficient. It is\n",
      "particularly effective for tasks requiring the retrieval of domain-specific code or documentation. With a lightweight,\n",
      "text-based web interface and modular navigation tools, the web agent traverses multiple websites, extract relevant\n",
      "segments, and return reasonable URLs or raw content.\n",
      "Tool Usage. The agent utilizes SimpleTextBrowser as its web interface and page-level control tools: VisitTool,\n",
      "PageUpTool, and PageDownTool to navigate webpages. For query-based lookups, it applies GoogleSearchTool for\n",
      "open web search and GithubSearchTool to identify reusable open-source tools. This design supports real-time code\n",
      "retrieval and context-aware tool planning.\n",
      "3.4 MCP Creation Component\n",
      "To enable the creativity of the agent, we design three tools collaboratively contributing to the MCP creation process.\n",
      "3.4.1 MCP Brainstorming\n",
      "Since LLMs often exhibit overconfidence in their capabilities [ 22], we introduce MCP Brainstorming to conduct\n",
      "preliminary capability assessment by providing both the task and the description of current framework. We designed spe-\n",
      "cialized prompts to facilitate accurate self-assessment of the agent’s capabilities. Moreover, whenMCP Brainstorming\n",
      "identifies insufficient capabilities of the framework to complete the task, it provides references for tool generation to\n",
      "bridge the capability gap. This provides prior guidance for subsequent tool selection and task planning required to\n",
      "accomplish given objectives.\n",
      "3.4.2 ScriptGeneratingTool\n",
      "The ScriptGeneratingTool is a code-building utility designed for constructing external tools. It receives explicit\n",
      "subtask descriptions and suggestions for code construction from the manager agent, and potentially useful GitHub links\n",
      "obtained via the web agent, which can provide information such as README.md files or code snippets from GitHub to\n",
      "guide the script generation process. Furthermore, ScriptGeneratingTool generates the environment script to create\n",
      "the required environment for the code running and the cleaning script to clean up redundant files and environments\n",
      "generated after script execution. Therefore, ScriptGeneratingTool ensures that the generated scripts are valid,\n",
      "self-contained, and executable, making them suitable for deployment in the given task, and reusable in the future.\n",
      "3.4.3 CodeRunningTool\n",
      "The CodeRunningTool validates the functionality of the generated script by executing it within an isolated environment.\n",
      "If the execution produces the expected results, the tool is registered in the system as a reusable MCP. This process also\n",
      "supports iterative refinement, allowing for error inspection and subsequent code regeneration to improve the script’s\n",
      "performance.\n",
      "3.4.4 Environment Management\n",
      "Upon retrieving or generating a candidate tool, the system activates the environment planner module. This module\n",
      "parses the relevant repository or script metadata such as README.md, requirements.txt, and shell scripts using\n",
      "the TextInspectorTool. It extracts and validates the dependencies and setup instructions to construct an isolated\n",
      "execution profile. Subsequently, a new Conda environment is created with a unique name (typically derived from the\n",
      "task ID or a hash of the repository path), and dependencies are installed using conda install or pip install.\n",
      "All runtime environments are initialized locally in parallel, obviating the need for administrative privileges or container-\n",
      "ization technologies. This approach ensures high compatibility across various tasks while preserving the portability\n",
      "5\n",
      "\n",
      "of the system. During execution, the environment is explicitly activated prior to invoking the code interpreter, thus\n",
      "ensuring both isolation and reproducibility.\n",
      "In the event of a failure during environment initialization—due to issues such as missing packages, syntax errors in setup\n",
      "scripts, or unavailable dependencies—Alita activates an automated recovery procedure. This procedure attempts various\n",
      "fallback strategies, including relaxing version constraints or identifying the minimal set of dependencies required for\n",
      "functionality. If these recovery attempts are unsuccessful, the tool is discarded, and the failure is logged for offline\n",
      "analysis and future investigation. This enables Alita to self-correct its designed tools, thereby generating more accurate\n",
      "and robust solutions.\n",
      "4 Experiments\n",
      "4.1 Experiment Setting\n",
      "4.1.1 Benchmarks\n",
      "To evaluate the general task-handling capabilities of Alita, we conducted extensive testing across multiple agent\n",
      "benchmarks.\n",
      "GAIA [10]: GAIA is a benchmark designed to assess the capabilities of general-purpose AI assistants. It consists of\n",
      "466 real-world scenario-based questions covering daily tasks, scientific reasoning, web browsing, and tool usage. While\n",
      "these tasks are conceptually simple for humans, they are challenging for most advanced AI systems.\n",
      "Mathvista [23]: MathVista is a comprehensive benchmark designed to evaluate the mathematical reasoning capabilities\n",
      "of foundation models within visual contexts. It can effectively evaluate the model’s capabilities in visual comprehension,\n",
      "mathematical reasoning, programming, and other related skills. Due to limitations in resources, we randomly selected\n",
      "100 samples from the dataset.\n",
      "Pathvqa [24]: PathVQA is a medical visual question answering dataset. It can effectively assess the agent’s capabilities\n",
      "across multiple dimensions, including visual understanding, spatial Reasoning, medical Knowledge search or integration,\n",
      "and natural language processing. Due to limitations in resources, we randomly selected 100 samples from the dataset.\n",
      "4.1.2 Baselines\n",
      "We include a variety of baselines for comparison. For the GAIA benchmark, there are more baselines available on the\n",
      "GAIA leaderboard3.\n",
      "Octotools [9]: OctoTools is a recent framework designed to streamline multi-tool workflows in complex computational\n",
      "tasks. With over 10 standardized tool cards encapsulating various functionalities, the agent gains powerful capabilities\n",
      "to handle multi-domain tasks.\n",
      "Open Deep Research-smolagents4 [25]: Open Deep Research is an open-source agent developed under Hugging\n",
      "Face’s Smolagents project, designed to automate complex multi-step research tasks. Alita’s development is largely\n",
      "based on the framework of Open Deep Research-smolagents. However, we remove many pre-defined tools and also add\n",
      "the MCP creation component to follow the design principle of minimal predefinition and maximal self-evolution.\n",
      "AutoAgent [17]: AutoAgent is a zero-code platform designed to facilitate the creation, customization, and deployment\n",
      "of agents powered by LLMs. By providing a natural language interface, it allows users to develop multi-agent systems,\n",
      "design workflows, and integrate tools without requiring technical expertise.\n",
      "OWL [8]: OWL is an open-source, multi-agent framework built on the CAMEL-AI platform, designed to support the\n",
      "automation of complex real-world tasks through dynamic agent collaboration. OWL decomposes tasks into specialized\n",
      "sub-tasks, each of which is managed by a distinct agent type—such as UserAgents, AssistantAgents, and ToolAgents.\n",
      "A-World [12]: A-World is an open-source multi-agent system framework designed to simplify the construction,\n",
      "evaluation, and deployment of general multi-agent tasks. Through its modular design, the framework supports\n",
      "autonomous decision-making, tool usage, and collaboration among agents.\n",
      "OpenAI Deep Research5: OpenAI’s Deep Research is an advanced AI agent integrated with ChatGPT, designed to\n",
      "autonomously perform multi-step research tasks by synthesizing information from diverse online sources. This agentic\n",
      "3https://huggingface.co/spaces/gaia-benchmark/leaderboard\n",
      "4https://huggingface.co/blog/open-deep-research\n",
      "5https://openai.com/index/introducing-deep-research/\n",
      "6\n",
      "\n",
      "framework excels in generating comprehensive reports on complex topics and has shown superior performance on\n",
      "benchmarks.\n",
      "4.2 Results\n",
      "We run three rounds of testing on GAIA and achieved the best performance on the GAIA leaderboard, surpassing\n",
      "other agent systems. Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and 87.27% pass@3 accuracy,\n",
      "which is top-ranking on the GAIA benchmark validation dataset, outperforming many agent systems with far greater\n",
      "complexity. Alita with Claude 3.7 Sonnet + GPT-4o achieves 72.73% pass@1 and 86.06% pass@3 on GAIA, and\n",
      "further attains 74.00% and 52.00% pass@1 on the Mathvista and PathVQA benchmarks, respectively, outperforming\n",
      "Octotools and Open Deep Research by smolagents. More detailed results are shown in Table 1.\n",
      "Agent\n",
      "GAIA Mathvista PathVQA\n",
      "level1 level2 level3 total\n",
      "Alita (Claude-3.7-Sonnet, GPT-4o) (%)\n",
      "pass@1 81.13 75.58 46.15 72.73 74 52\n",
      "pass@2 88.68 80.23 53.85 78.79 - -\n",
      "pass@3 96.23 86.04 65.38 86.06 - -\n",
      "Alita (Claude-Sonnet-4, GPT-4o) (%)\n",
      "pass@1 77.36 76.74 65.38 75.15 - -\n",
      "pass@3 88.68 89.53 76.92 87.27 - -\n",
      "Baselines (%)\n",
      "Octotools - - - 18.40 68 47\n",
      "ODR-smolagents 67.92 53.49 34.62 55.15 65 42\n",
      "AutoAgent 71.70 53.49 26.92 55.15 - -\n",
      "OWL 84.91 67.44 42.31 69.09 - -\n",
      "A-World 86.79 69.77 34.62 69.70 - -\n",
      "OpenAI-DR 74.29 69.06 47.60 67.36 - -\n",
      "Table 1: Performance comparison of Alita and baseline agent systems on the GAIA, Mathvista, and PathVQA\n",
      "benchmarks. ODR-Smolagents refers to the Open Deep Research agent in the Smolagents framework. OpenAI-DR\n",
      "refers to OpenAI’s Deep Research. The table presents the accuracy at different levels of difficulty for GAIA, as well as\n",
      "the overall performance on Mathvista and PathVQA. The pass@1, pass@2, and pass@3 denote the accuracy achieved\n",
      "by running the Alita framework 1, 2, and 3 times, respectively, and selecting the best answer. Alita outperforms all\n",
      "baseline agents across the GAIA levels, achieving the highest total accuracy.\n",
      "5 Analysis\n",
      "5.1 Reuse of Alita-Generated MCPs\n",
      "5.1.1 Overview\n",
      "We collect the MCPs generated from running the GAIA dataset using Alita in conjunction with powerful models\n",
      "(Claude-3.7-Sonnet and GPT-4o). The benefits of reusing Alita-generated MCPs are two-fold. First, these MCPs can be\n",
      "reused by other agent frameworks and improve their performance since Alita, instead of human developers, designs a\n",
      "set of useful MCPs fit to GAIA by trial and error. Second, these MCPs can be reused by agents with smaller LLMs\n",
      "and significantly improve the performance. The reuse of auto-generated MCPs for agents with smaller LLMs can be\n",
      "viewed as a new way of distillation from larger LLMs. Traditionally, distillation might be fine-tuning smaller LLMs on\n",
      "data generated by larger LLMs. In comparison, the reuse of MCPs generated from agents with larger LLMs is much\n",
      "easier, cheaper, and faster than traditional distillation.\n",
      "7\n",
      "\n",
      "5.1.2 Reuse by Open Deep Research-smolagents\n",
      "We run open Deep Research-smolagents [25] on GAIA with and without Alita-generated MCPs based on GPT-4o. The\n",
      "results are presented in Table 2. From this experiment, we observe that the reuse of Alita-generated MCPs results in\n",
      "better performance compared to the base framework for all difficulty levels. This demonstrates that Alita can generate\n",
      "very useful MCPs, which can be provided to other agents, helping them enhance their capabilities and solve problems\n",
      "that would otherwise be unsolvable. Additionally, the consistent improvement across all difficulty levels indicates that\n",
      "Alita’s MCPs provide generalizable utility rather than just addressing specific edge cases in the dataset.\n",
      "Model Configuration Level 1 Level 2 Level 3 Total\n",
      "ODR-smolagents + GPT-4o(No Alita MCPs) 33.96% 29.07% 11.54% 27.88%\n",
      "ODR-smolagents + GPT-4o(With Alita MCPs) 39.62% 36.05% 15.38% 33.94%\n",
      "Table 2: Comparison of performance between ODR-smolagents with and without Alita-generated MCPs. The results\n",
      "are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\n",
      "performance at the respective GAIA levels. The reuse of Alita-generated MCPs can enhance the performance of other\n",
      "agents.\n",
      "5.1.3 Reuse by Base Agent on Smaller LLM\n",
      "We reuse MCPs in the base framework, i.e., ODR-smolagents [25], without the MCP creation component in Alita, and\n",
      "also with some extra pre-defined tools used in ODR-smolagents based on GPT-4o-mini. The results are presented in\n",
      "Table 3.\n",
      "Model Configuration Level 1 Level 2 Level 3 Average\n",
      "Base Framework + GPT-4o-mini (No Alita MCP) 32.08% 20.93% 3.85% 21.82%\n",
      "Base Framework + GPT-4o-mini (With Alita MCP) 39.62% 27.91% 11.54% 29.09%\n",
      "Table 3: Comparison of performance between the base framework on GPT-4o-mini, with and without Alita-generated\n",
      "MCPs. The results are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column\n",
      "corresponds to the performance at the respective GAIA levels. The reuse of Alita-generated MCPs significantly\n",
      "enhances the performance of agents on smaller LLMs.\n",
      "From this experiment, we observe that the reuse of Alita-generated MCPs significantly improves performance over the\n",
      "base framework based on a smaller LLM. This is because the Alita-generated MCPs can be considered MCPs distilled\n",
      "from powerful models (Claude-3.7-Sonnet), which are made available for agents on smaller LLMs. This helps bridge\n",
      "the gap between the agents on smaller LLMs and agents on larger LLMs in certain domains, thereby enhancing its\n",
      "task-processing capabilities. Especially for Level 3, we observe a particularly dramatic improvement with the accuracy\n",
      "tripling from 3.85% to 11.54%. This substantial improvement on the most challenging problems demonstrates that\n",
      "Alita-generated MCPs are especially valuable for complex reasoning tasks where agents on smaller LLMs typically\n",
      "struggle the most. The MCPs effectively encapsulate sophisticated problem-solving capabilities that the smaller model\n",
      "can leverage without needing to develop the full reasoning chain independently.\n",
      "5.2 Alita on Smaller LLM\n",
      "We hypothesize that Alita will be even stronger with the increasing coding and reasoning capabilities of LLMs in\n",
      "the future. To validate our performance, we run Alita on GAIA using GPT-4o-mini instead of Claude-3.7-Sonnet. The\n",
      "results can be found in Table 4. Different to the experiment in Section 5.1.3, the agent doesn’t have distilled MCPs - the\n",
      "agent on GPT-4o-mini model must generate its own MCPs. The results are presented in Table 4.\n",
      "From this experiment, on one hand, we observe that Alita, after replacing the models with GPT-4o-mini, performs\n",
      "significantly worse on GAIA. This substantial performance gap highlights the critical role of the underlying models’\n",
      "coding capabilities. On the other hand, the performance of Alita increases rapidly as the capabilities of the underlying\n",
      "models improve. We can expect that with future updates to the LLMs, Alita’s performance will continue to strengthen,\n",
      "surpassing its current capabilities. The design of future generalist agents might be much simpler in the future, without\n",
      "any predefined tools and workflows for direct problem-solving. Instead, human developers might focus on designing\n",
      "modules for enabling and stimulating the creativity and evolution of generalist agents.\n",
      "8\n",
      "\n",
      "Model Configuration Level 1 Level 2 Level 3 Total\n",
      "Alita (Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% 72.73%\n",
      "Alita (GPT-4o-mini) 54.72% 44.19% 19.23% 43.64%\n",
      "Table 4: Comparison of performance between Alita(Claude-3.7-Sonnet,GPT-4o) and Alita(GPT-4o-mini). The results\n",
      "are reported at different GAIA levels: Level 1, Level 2, Level 3, and the average. Each column corresponds to the\n",
      "performance at the respective GAIA levels. The integration of a smaller model significantly reduces the performance.\n",
      "5.3 Case Study\n",
      "To investigate Alita’s workflow when tackling tasks, we conducted a case study on its approach to solving a Level 3\n",
      "difficult problem in GAIA. The details of this process are presented in Appendix A. From the case study, we observe\n",
      "that Alita is able to perform a structured MCP brainstorming session based on the task at hand, effectively identifying\n",
      "and utilizing relevant resources to implement a feasible MCP that aids in completing the task.\n",
      "6 Conclusion\n",
      "In this work, we introduced Alita, a generalist agent designed with the principles of minimal predefinition and maximal\n",
      "self-evolution. By significantly reducing reliance on manually predefined tools and workflows for direct solving,\n",
      "Alita leverages creative, autonomous capabilities in real time, facilitating scalable agentic reasoning. Our approach\n",
      "demonstrates that simplicity in design does not undermine, but rather enhances, the performance and adaptability of\n",
      "generalist agents.\n",
      "9\n",
      "\n",
      "References\n",
      "[1] OpenAI. Introducing deep research.\n",
      "[2] Noam Kolt. Governing ai agents. arXiv preprint arXiv:2501.07913, 2025.\n",
      "[3] Jian Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian, Yanghua Xiao, and Yu Su.\n",
      "Travelplanner: A benchmark for real-world planning with language agents. arXiv preprint arXiv:2402.01622,\n",
      "2024.\n",
      "[4] Tianbao Xie, Danyang Zhang, Jixuan Chen, Xiaochuan Li, Siheng Zhao, Ruisheng Cao, Toh J Hua, Zhoujun\n",
      "Cheng, Dongchan Shin, Fangyu Lei, et al. Osworld: Benchmarking multimodal agents for open-ended tasks in\n",
      "real computer environments. Advances in Neural Information Processing Systems, 37:52040–52094, 2024.\n",
      "[5] Hongru Wang, Rui Wang, Boyang Xue, Heming Xia, Jingtao Cao, Zeming Liu, Jeff Z. Pan, and Kam-Fai Wong.\n",
      "AppBench: Planning of multiple APIs from various APPs for complex user instruction. In Yaser Al-Onaizan,\n",
      "Mohit Bansal, and Yun-Nung Chen, editors,Proceedings of the 2024 Conference on Empirical Methods in Natural\n",
      "Language Processing, pages 15322–15336, Miami, Florida, USA, November 2024. Association for Computational\n",
      "Linguistics.\n",
      "[6] Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin\n",
      "Li, Shijue Huang, Wanjun Zhong, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli\n",
      "Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao\n",
      "Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, and Guang Shi. Ui-tars:\n",
      "Pioneering automated gui interaction with native agents, 2025.\n",
      "[7] Junde Wu, Jiayuan Zhu, and Yuyuan Liu. Agentic reasoning: Reasoning llms with tools for the deep research.\n",
      "arXiv preprint arXiv:2502.04644, 2025.\n",
      "[8] Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, Tao Sun, Ziyu Ye, Zhaoxuan Jin, Yingru\n",
      "Li, Zeyu Zhang, Yifeng Wang, Qianshuo Ye, Ping Luo, and Guohao Li. Owl: Optimized workforce learning for\n",
      "general multi-agent assistance in real-world task automation, 2025.\n",
      "[9] Pan Lu, Bowen Chen, Sheng Liu, Rahul Thapa, Joseph Boen, and James Zou. Octotools: An agentic framework\n",
      "with extensible tools for complex reasoning. arXiv preprint arXiv:2502.11271, 2025.\n",
      "[10] Grégoire Mialon, Clémentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom. Gaia: a benchmark for\n",
      "general ai assistants. In The Twelfth International Conference on Learning Representations, 2023.\n",
      "[11] Xun Jiang, Feng Li, Han Zhao, Jiaying Wang, Jun Shao, Shihao Xu, Shu Zhang, Weiling Chen, Xavier Tang, Yize\n",
      "Chen, et al. Long term memory: The foundation of ai self-evolution. arXiv preprint arXiv:2410.15665, 2024.\n",
      "[12] Agent Team at Ant Group. Aworld: A unified agent playground for computer and phone use tasks, 2025.\n",
      "[13] Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan, Eduardo Salinas, Erkang, Zhu, Friederike Niedtner,\n",
      "Grace Proebsting, Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang, Ricky Loynd, Robert West, Victor\n",
      "Dibia, Ahmed Awadallah, Ece Kamar, Rafah Hosn, and Saleema Amershi. Magentic-one: A generalist multi-agent\n",
      "system for solving complex tasks, 2024.\n",
      "[14] Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, Börje F Karlsson, Jie Fu, and Yemin Shi.\n",
      "Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:2309.17288, 2023.\n",
      "[15] Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song,\n",
      "Bowen Li, Jaskirat Singh, et al. Openhands: An open platform for ai software developers as generalist agents. In\n",
      "The Thirteenth International Conference on Learning Representations, 2024.\n",
      "[16] Jiayi Zhang, Jinyu Xiang, Zhaoyang Yu, Fengwei Teng, Xionghui Chen, Jiaqi Chen, Mingchen Zhuge, Xin Cheng,\n",
      "Sirui Hong, Jinlin Wang, et al. Aflow: Automating agentic workflow generation. arXiv preprint arXiv:2410.10762,\n",
      "2024.\n",
      "[17] Jiabin Tang, Tianyu Fan, and Chao Huang. Autoagent: A fully-automated and zero-code framework for llm agents.\n",
      "arXiv e-prints, pages arXiv–2502, 2025.\n",
      "[18] Lifan Yuan, Yangyi Chen, Xingyao Wang, Yi R Fung, Hao Peng, and Heng Ji. Craft: Customizing llms by creating\n",
      "and retrieving from specialized toolsets. arXiv preprint arXiv:2309.17428, 2023.\n",
      "[19] Zhiruo Wang, Daniel Fried, and Graham Neubig. Trove: Inducing verifiable and efficient toolboxes for solving\n",
      "programmatic tasks. arXiv preprint arXiv:2401.12869, 2024.\n",
      "[20] Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. Creator: Tool creation for disentangling\n",
      "abstract and concrete reasoning of large language models. arXiv preprint arXiv:2305.14318, 2023.\n",
      "10\n",
      "\n",
      "[21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented\n",
      "generation. arXiv preprint arXiv:2505.03275, 2025.\n",
      "[22] Fengfei Sun, Ningke Li, Kailong Wang, and Lorenz Goette. Large language models are overconfident and amplify\n",
      "human bias. 2025.\n",
      "[23] Pan Lu, Hritik Bansal, Tony Xia, Jiacheng Liu, Chunyuan Li, Hannaneh Hajishirzi, Hao Cheng, Kai-Wei Chang,\n",
      "Michel Galley, and Jianfeng Gao. Mathvista: Evaluating mathematical reasoning of foundation models in visual\n",
      "contexts. In International Conference on Learning Representations (ICLR), 2024.\n",
      "[24] Xuehai He, Yichen Zhang, Luntian Mou, Eric P. Xing, and Pengtao Xie. Pathvqa: 30000+ questions for medical\n",
      "visual question answering. ArXiv, abs/2003.10286, 2020.\n",
      "[25] Aymeric Roucher, Albert Villanova del Moral, Thomas Wolf, Leandro von Werra, and Erik Kaunismäki. ‘smo-\n",
      "lagents‘: a smol library to build great agentic systems. https://github.com/huggingface/smolagents,\n",
      "2025.\n",
      "11\n",
      "\n",
      "A Detailed Case Study\n",
      "Case Study: YouTube 360 VR Video Subtitle Extraction\n",
      "Question ID: 0512426f-4d28-49f0-be77-06d05daec096\n",
      "Question: In the YouTube 360 VR video from March 2018 narrated by the voice actor of Lord of the Rings’\n",
      "Gollum, what number was mentioned by the narrator directly after dinosaurs were first shown in the video?\n",
      "Our Answer: 100000000\n",
      "Correct Answer: 100000000\n",
      "Is Correct: Yes\n",
      "Generated MCP: YouTube Video Subtitle Crawler\n",
      "Alita Workflow:\n",
      "1. MCP Brainstorming: Alita propose the development of a \"YouTube Video Subtitle Crawler\" MCP, which\n",
      "should automate the extraction of subtitles from a given YouTube video. This involves scraping the subtitles of\n",
      "the video and processing them to isolate the relevant text after the event in question.\n",
      "2. Web Agent Execution: To implement the subtitle extraction, a search is conducted in open-source\n",
      "repositories to find relevant tools that can assist in extracting YouTube video transcripts. An appropriate tool,\n",
      "the youtube-transcript-api, is identified from the following GitHub repository:\n",
      "https://github.com/jdepoix/youtube-transcript-api\n",
      "3. Manager Agent: The Manager Agent synthesizes the information from the GitHub repository and proceeds\n",
      "to write a Python function that leverages the youtube-transcript-api to retrieve the transcript of the video with\n",
      "corresponding environment setup instructions.\n",
      "The environment setup and installation steps are defined as follows:\n",
      "conda create -n youtube_transcript\n",
      "conda activate youtube_transcript\n",
      "pip install youtube-transcript-api\n",
      "The Python code to retrieve the video transcript is as follows:\n",
      "from youtube_transcript_api import YouTubeTranscriptApi\n",
      "# Initialize the API\n",
      "ytt_api = YouTubeTranscriptApi()\n",
      "# Retrieve the transcript\n",
      "video_id = ...\n",
      "transcript_list = ytt_api.list(’video_id’)\n",
      "...\n",
      "4. Manager Agent Execution: Leveraging the Python code and the established environment, the Manager\n",
      "Agent successfully packaged the YouTube Video Subtitle Crawler MCP. Subsequently, this MCP was employed\n",
      "to efficiently scrape the subtitles from the video, enabling the extraction of the relevant content. After analyzing\n",
      "the content, the correct number (100000000) mentioned by the narrator following the dinosaur scene is extracted\n",
      "from the transcript.\n",
      "5. Final Output: The number \"100000000\" is identified as the correct answer.\n",
      "B Limitations\n",
      "Alita highly relies on the coding capability of LLM. When the LLM’s coding capability is really poor, our method will\n",
      "perform worse than traditional generalist agent.\n",
      "12\n",
      "\n",
      "[[ ## question ## ]]\n",
      "How does ALITA help LLMs to achieve autonomous reasoning?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "ALITA enables large language models (LLMs) to perform autonomous reasoning by adopting a design philosophy of **minimal predefinition and maximal self‑evolution**.  \n",
      "Key mechanisms include:\n",
      "\n",
      "1. **MCP Brainstorming** – The LLM first introspects the task, identifies missing capabilities, and proposes new *Model‑agnostic Toolchains* (MCPs) that can be built on‑the‑fly.  \n",
      "2. **Web Agent Retrieval** – It searches public code repositories and APIs to find existing libraries that can implement the proposed MCP, thereby avoiding the need for the model to write code from scratch.  \n",
      "3. **Dynamic Environment Construction** – The LLM generates the necessary environment‑setup commands (e.g., conda or pip installs) and integrates them with the retrieved code.  \n",
      "4. **Self‑Generated MCP Packaging** – The model packages the retrieved code and environment instructions into a reusable MCP, which can be invoked as a tool for the current task.  \n",
      "5. **Iterative Refinement** – If the first attempt fails, the model can regenerate the MCP or adjust its reasoning chain, effectively learning from its own failures.  \n",
      "\n",
      "By allowing the model to **create, evolve, and reuse tools in real time**, ALITA turns the LLM into an autonomous reasoner that no longer relies on a fixed set of pre‑built tools or workflows. This self‑evolving capability scales with the underlying model’s coding and reasoning power, enabling more complex, multi‑step problem solving without human‑written tool libraries.  \n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e6bf1",
   "metadata": {},
   "source": [
    "# 2. Programmatic Signatures and how they integrate with the broader LLM ecosystem\n",
    "In general, you will have to use DSPy for any (or only the final) LLM centric operation because it is focused on LLM prompting. Every other operation (tool, vector database, etc.) can come from any other framework!\n",
    "\n",
    "> We use LlamaIndex to provide vector indexing capabilities here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0c961",
   "metadata": {},
   "source": [
    "Creating a vector database to ingest our documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a812d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "Settings.embed_model = OllamaEmbedding(model_name=\"nomic-embed-text\")\n",
    "\n",
    "index = VectorStoreIndex(docs, embed_model=Settings.embed_model)\n",
    "\n",
    "base_retriever = index.as_retriever(similarity_top_k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90c6788c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = base_retriever.retrieve(question)\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04db3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    context = dspy.InputField(desc=\"May contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Often between 1-10 sentences.\")\n",
    "\n",
    "class RewriteQuestion(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    rewritten_questions: list[str] = dspy.OutputField(\n",
    "        desc=\"Decompose this question into sub questions or rewrite the original user question if necessary to improve retrieval from a vector database. Otherwise return the original question.\"\n",
    "    )\n",
    "    \n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.retriever = base_retriever\n",
    "        self.rewriter = dspy.Predict(RewriteQuestion)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.consolidate_answer = dspy.Predict(\n",
    "            dspy.Signature(\n",
    "                'original_question: str, sub_answers: list[str] -> consolidated_answer:str',\n",
    "                instructions=\"Consolidate the sub answers into a coherent answer within a few paragraphs that answers the original question.\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def query_rewrite(self, question: str):\n",
    "        return self.rewriter(question=question)\n",
    "    \n",
    "    def forward(self, question: str):\n",
    "        question_rewrite = self.query_rewrite(question)\n",
    "        sub_answers = []\n",
    "        for q in tqdm(question_rewrite.rewritten_questions):\n",
    "            print(f\"\\n----\\nProcessing question: {q}\")            \n",
    "            context = self.retriever.retrieve(q) #the LlamaIndex component\n",
    "            sub_answer = self.generate_answer(context=context, question=q)\n",
    "            print(f\"\\nAnswer to {q}: {sub_answer}\")\n",
    "            print(f\"\\nSub question answer reasoning: {sub_answer.reasoning}\\n----\\n\")\n",
    "            sub_answers.append(sub_answer)\n",
    "        prediction = self.consolidate_answer(original_question=question, sub_answers=sub_answers)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8209169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4c7478ca86401889765781804d3de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n",
      "Processing question: How does an agent become autonomous with Atila?\n",
      "\n",
      "Answer to How does an agent become autonomous with Atila?: Prediction(\n",
      "    reasoning='The question asks for a concise explanation of how an agent achieves autonomy using the Alita framework. Based on the provided context, Alita is a generalist agent that relies on minimal predefined tools and workflows, instead using a manager–planner–executor architecture that allows the agent to self‑evolve and adapt to diverse tasks. The answer should highlight these key design choices that enable autonomy.',\n",
      "    answer='Alita achieves autonomy by using a minimal‑predefinition, self‑evolving architecture: a manager coordinates a planner that generates step‑by‑step plans, and an executor carries them out. The agent learns and refines its own tools and workflows on the fly, requiring no extensive manual design, which lets it adapt and act independently across varied tasks.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The question asks for a concise explanation of how an agent achieves autonomy using the Alita framework. Based on the provided context, Alita is a generalist agent that relies on minimal predefined tools and workflows, instead using a manager–planner–executor architecture that allows the agent to self‑evolve and adapt to diverse tasks. The answer should highlight these key design choices that enable autonomy.\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "Processing question: Does Alita use the Model Context Protocol?\n",
      "\n",
      "Answer to Does Alita use the Model Context Protocol?: Prediction(\n",
      "    reasoning='The provided documents describe Alita as a generalist agent that relies on minimal predefinition and maximal self‑evolution, but none of the excerpts mention the Model Context Protocol or any related terminology. No evidence indicates that Alita incorporates or depends on the Model Context Protocol.',\n",
      "    answer='No, the available information does not indicate that Alita uses the Model Context Protocol.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The provided documents describe Alita as a generalist agent that relies on minimal predefinition and maximal self‑evolution, but none of the excerpts mention the Model Context Protocol or any related terminology. No evidence indicates that Alita incorporates or depends on the Model Context Protocol.\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "Processing question: Does Alita write its own tools?\n",
      "\n",
      "Answer to Does Alita write its own tools?: Prediction(\n",
      "    reasoning='The cited documents describe Alita as a generalist agent that achieves scalable reasoning with a “radically simple design” and “minimal predefinition.”  It explicitly states that Alita “uses no complex predefined tools and workflows for specific tasks” and instead relies on self‑evolution to handle diverse tasks.  There is no mention of Alita generating or writing its own tools.',\n",
      "    answer='No. Alita does not write its own tools; it operates with minimal predefined tools and relies on self‑evolution to handle tasks.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The cited documents describe Alita as a generalist agent that achieves scalable reasoning with a “radically simple design” and “minimal predefinition.”  It explicitly states that Alita “uses no complex predefined tools and workflows for specific tasks” and instead relies on self‑evolution to handle diverse tasks.  There is no mention of Alita generating or writing its own tools.\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "Processing question: Where are the tools deployed?\n",
      "\n",
      "Answer to Where are the tools deployed?: Prediction(\n",
      "    reasoning='The question asks for the location of tool deployment in the Alita system. The provided context states that the manager agent “embraces Alita’s minimal philosophy by employing concise but powerful toolkits, including MCP Brainstorming, ScriptGeneratingTool and CodeRunningTool.” This indicates that the tools are integrated and executed within the manager agent component of Alita.',\n",
      "    answer='The tools are deployed inside Alita’s manager agent, which orchestrates the agent’s reasoning and execution.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The question asks for the location of tool deployment in the Alita system. The provided context states that the manager agent “embraces Alita’s minimal philosophy by employing concise but powerful toolkits, including MCP Brainstorming, ScriptGeneratingTool and CodeRunningTool.” This indicates that the tools are integrated and executed within the manager agent component of Alita.\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "engine = RAG()\n",
    "pred = engine(\n",
    "    \"How Agent become autonomous with Atila? Alita use Model context protocol? It write own tools? Tools deploy where?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c56ea0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alita achieves autonomy through a lightweight, self‑evolving architecture. A manager agent coordinates a planner that generates step‑by‑step plans, and an executor carries them out. Because Alita relies on minimal predefined tools and workflows, it can learn, refine, and create new tools on the fly, allowing it to adapt to a wide range of tasks without extensive manual configuration.\n",
       "\n",
       "There is no evidence that Alita incorporates the Model Context Protocol; the available information does not mention this protocol in its design.\n",
       "\n",
       "Alita does not write its own tools. Instead, it operates with a small set of core, pre‑defined tools (such as MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool) and expands its capabilities through self‑evolution rather than generating new tools from scratch.\n",
       "\n",
       "The tools are deployed inside Alita’s manager agent. The manager orchestrates the reasoning and execution flow, invoking the appropriate toolkits as needed during the planning and execution stages."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(pred.consolidated_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0db390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-12T22:03:12.246244]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `original_question` (str): \n",
      "2. `sub_answers` (list[str]):\n",
      "Your output fields are:\n",
      "1. `consolidated_answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## original_question ## ]]\n",
      "{original_question}\n",
      "\n",
      "[[ ## sub_answers ## ]]\n",
      "{sub_answers}\n",
      "\n",
      "[[ ## consolidated_answer ## ]]\n",
      "{consolidated_answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Consolidate the sub answers into a coherent answer within a few paragraphs that answers the original question.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## original_question ## ]]\n",
      "How Agent become autonomous with Atila? Alita use Model context protocol? It write own tools? Tools deploy where?\n",
      "\n",
      "[[ ## sub_answers ## ]]\n",
      "[Prediction(\n",
      "    reasoning='The question asks for a concise explanation of how an agent achieves autonomy using the Alita framework. Based on the provided context, Alita is a generalist agent that relies on minimal predefined tools and workflows, instead using a manager–planner–executor architecture that allows the agent to self‑evolve and adapt to diverse tasks. The answer should highlight these key design choices that enable autonomy.',\n",
      "    answer='Alita achieves autonomy by using a minimal‑predefinition, self‑evolving architecture: a manager coordinates a planner that generates step‑by‑step plans, and an executor carries them out. The agent learns and refines its own tools and workflows on the fly, requiring no extensive manual design, which lets it adapt and act independently across varied tasks.'\n",
      "), Prediction(\n",
      "    reasoning='The provided documents describe Alita as a generalist agent that relies on minimal predefinition and maximal self‑evolution, but none of the excerpts mention the Model Context Protocol or any related terminology. No evidence indicates that Alita incorporates or depends on the Model Context Protocol.',\n",
      "    answer='No, the available information does not indicate that Alita uses the Model Context Protocol.'\n",
      "), Prediction(\n",
      "    reasoning='The cited documents describe Alita as a generalist agent that achieves scalable reasoning with a “radically simple design” and “minimal predefinition.”  It explicitly states that Alita “uses no complex predefined tools and workflows for specific tasks” and instead relies on self‑evolution to handle diverse tasks.  There is no mention of Alita generating or writing its own tools.',\n",
      "    answer='No. Alita does not write its own tools; it operates with minimal predefined tools and relies on self‑evolution to handle tasks.'\n",
      "), Prediction(\n",
      "    reasoning='The question asks for the location of tool deployment in the Alita system. The provided context states that the manager agent “embraces Alita’s minimal philosophy by employing concise but powerful toolkits, including MCP Brainstorming, ScriptGeneratingTool and CodeRunningTool.” This indicates that the tools are integrated and executed within the manager agent component of Alita.',\n",
      "    answer='The tools are deployed inside Alita’s manager agent, which orchestrates the agent’s reasoning and execution.'\n",
      ")]\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## consolidated_answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## consolidated_answer ## ]]\n",
      "Alita achieves autonomy through a lightweight, self‑evolving architecture. A manager agent coordinates a planner that generates step‑by‑step plans, and an executor carries them out. Because Alita relies on minimal predefined tools and workflows, it can learn, refine, and create new tools on the fly, allowing it to adapt to a wide range of tasks without extensive manual configuration.\n",
      "\n",
      "There is no evidence that Alita incorporates the Model Context Protocol; the available information does not mention this protocol in its design.\n",
      "\n",
      "Alita does not write its own tools. Instead, it operates with a small set of core, pre‑defined tools (such as MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool) and expands its capabilities through self‑evolution rather than generating new tools from scratch.\n",
      "\n",
      "The tools are deployed inside Alita’s manager agent. The manager orchestrates the reasoning and execution flow, invoking the appropriate toolkits as needed during the planning and execution stages.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb4d830",
   "metadata": {},
   "source": [
    "# 3. Creating agents with DSPy\n",
    "Agents in DSPy require tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4f34855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGAgentSignature(dspy.Signature):\n",
    "    question: str = dspy.InputField()\n",
    "    history: dspy.History = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "class AskForMoreInfo(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    response = dspy.OutputField()\n",
    "\n",
    "def ask_for_clarification_tool(question: str):\n",
    "    \"\"\"Use this tool if the user's question is unclear. This tool prompts the user for more information\"\"\"\n",
    "    clarification = dspy.Predict(\n",
    "        AskForMoreInfo(\n",
    "            question=question,\n",
    "            instructions=\"The user has asked an ambiguous question. Ask the user for clarifications to the question.\"\n",
    "        )\n",
    "    )\n",
    "    return clarification.response\n",
    "\n",
    "def query_alita_knowledge_base(question: str):\n",
    "    \"\"\"Use this tool to query the knowledge base on Alita.\"\"\"\n",
    "    engine = RAG()\n",
    "    pred = engine(question)\n",
    "    return pred.consolidated_answer\n",
    "\n",
    "history = dspy.History(messages=[])\n",
    "agent = dspy.ReAct(RAGAgentSignature, tools=[query_alita_knowledge_base, ask_for_clarification_tool,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a77c71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent(question=\"jkok\", history=history)\n",
    "history.messages.append({\"question\": \"jkok\", **response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "414370dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Could you please clarify what you mean by “jkok”? Are you asking for information about a topic, a location, or something else?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87c4f6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159de59ee547432ea1b16fcffbf2ec74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n",
      "Processing question: What steps are required for an agent to become autonomous using Alita?\n",
      "\n",
      "Answer to What steps are required for an agent to become autonomous using Alita?: Prediction(\n",
      "    reasoning='The question asks for the procedural steps that an agent must follow to achieve autonomy when using the Alita framework. Based on the provided documents, Alita’s design emphasizes minimal predefinition, self‑generated planning, execution, and iterative self‑evolution. Therefore, the key steps are: (1) supply a high‑level goal or task description; (2) let Alita generate a multi‑step plan (MCP) without relying on pre‑built tools; (3) execute the plan, allowing the agent to perform actions; (4) evaluate outcomes and gather feedback; (5) refine the plan or internal models through self‑evolution; and (6) repeat the cycle until the task is completed autonomously.',\n",
      "    answer='1. Provide a high‑level goal or task description.  \\n2. Alita generates a multi‑step plan (MCP) with minimal pre‑defined tools.  \\n3. Execute the plan, performing the required actions.  \\n4. Evaluate the results and collect feedback.  \\n5. Refine the plan or internal models through self‑evolution.  \\n6. Iterate the cycle until the task is completed autonomously.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The question asks for the procedural steps that an agent must follow to achieve autonomy when using the Alita framework. Based on the provided documents, Alita’s design emphasizes minimal predefinition, self‑generated planning, execution, and iterative self‑evolution. Therefore, the key steps are: (1) supply a high‑level goal or task description; (2) let Alita generate a multi‑step plan (MCP) without relying on pre‑built tools; (3) execute the plan, allowing the agent to perform actions; (4) evaluate outcomes and gather feedback; (5) refine the plan or internal models through self‑evolution; and (6) repeat the cycle until the task is completed autonomously.\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "Processing question: What does it mean for an agent to be autonomous in Alita?\n",
      "\n",
      "Answer to What does it mean for an agent to be autonomous in Alita?: Prediction(\n",
      "    reasoning='The question asks for a concise definition of “autonomous” as used in the context of Alita.  From the cited documents, Alita is described as a generalist agent that “enables scalable agentic reasoning with minimal predefinition and maximal self‑evolution” and “has rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight.”  Thus, autonomy for Alita means the agent can independently plan, reason, and execute tasks without relying on extensive manually‑designed tools or continuous human supervision.',\n",
      "    answer='In Alita, an agent is autonomous when it can independently plan, reason, and carry out complex tasks on its own, requiring only minimal human oversight and no extensive pre‑defined tools or workflows.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: The question asks for a concise definition of “autonomous” as used in the context of Alita.  From the cited documents, Alita is described as a generalist agent that “enables scalable agentic reasoning with minimal predefinition and maximal self‑evolution” and “has rapidly evolved from merely generating text to autonomous agents capable of independently planning and executing complex tasks on behalf of users with limited human oversight.”  Thus, autonomy for Alita means the agent can independently plan, reason, and execute tasks without relying on extensive manually‑designed tools or continuous human supervision.\n",
      "----\n",
      "\n",
      "\n",
      "----\n",
      "Processing question: What are the prerequisites for agent autonomy in Alita?\n",
      "\n",
      "Answer to What are the prerequisites for agent autonomy in Alita?: Prediction(\n",
      "    reasoning='Alita’s design philosophy emphasizes that an autonomous agent should not depend on elaborate, task‑specific tooling.  The paper states that autonomy is achieved through two key prerequisites: (1) **minimal predefinition** – the agent is given only a very small set of generic instructions or primitives, and (2) **maximal self‑evolution** – it can learn, adapt, and compose new strategies on its own during execution.  Together with its generalist architecture, these prerequisites allow Alita to perform complex tasks without extensive manual configuration.',\n",
      "    answer='Alita’s agent autonomy is built on two main prerequisites: minimal predefinition (only a few generic instructions or primitives are supplied) and maximal self‑evolution (the agent learns, adapts, and composes new strategies during execution). These enable it to operate without complex, task‑specific tools or workflows.'\n",
      ")\n",
      "\n",
      "Sub question answer reasoning: Alita’s design philosophy emphasizes that an autonomous agent should not depend on elaborate, task‑specific tooling.  The paper states that autonomy is achieved through two key prerequisites: (1) **minimal predefinition** – the agent is given only a very small set of generic instructions or primitives, and (2) **maximal self‑evolution** – it can learn, adapt, and compose new strategies on its own during execution.  Together with its generalist architecture, these prerequisites allow Alita to perform complex tasks without extensive manual configuration.\n",
      "----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "An agent becomes autonomous with Alita by following a simple, self‑driven cycle that relies on minimal pre‑definition and maximal self‑evolution:\n",
       "\n",
       "1. **Set a high‑level goal** – The user supplies only a brief, abstract task description.  \n",
       "2. **Generate a multi‑step plan** – Alita’s core planner creates a detailed plan (MCP) using only generic primitives, without needing a library of task‑specific tools.  \n",
       "3. **Execute the plan** – The agent carries out the actions, interacting with the environment or APIs as required.  \n",
       "4. **Evaluate and gather feedback** – After each step, the agent assesses the outcome, noting successes, failures, and any new information.  \n",
       "5. **Refine internally** – Using the feedback, the agent updates its internal models, composes new strategies, or adjusts the plan—this is the self‑evolution phase.  \n",
       "6. **Iterate until completion** – The cycle repeats until the original goal is achieved, with the agent requiring only minimal human oversight.\n",
       "\n",
       "In this framework, autonomy means the agent can independently plan, reason, and execute complex tasks without relying on extensive, manually designed tools or continuous human supervision. The combination of minimal pre‑definition and maximal self‑evolution allows Alita to adapt and compose new solutions on the fly, achieving true agentic behavior."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clarified_question = \"Sorry I accidentally sent that message. Here's the question I intended to ask: How does an agent become autonomous with Alita?\"\n",
    "response = agent(question=clarified_question, history=history)\n",
    "display(Markdown(response.answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ea017",
   "metadata": {},
   "source": [
    "# 4. Prompt Optimization\n",
    "To redo this using oss20b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ae9d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 22:13:30 INFO mlflow.tracking.fluent: Experiment with name 'gsm8k' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2', creation_time=1755008010365, experiment_id='2', last_update_time=1755008010365, lifecycle_stage='active', name='gsm8k', tags={}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')\n",
    "mlflow.set_experiment('gsm8k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c07a329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2409cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen25 = dspy.LM(\n",
    "    \"ollama_chat/qwen2.5:latest\", \n",
    "    api_base=\"http://localhost:11434\", \n",
    "    api_key=\"fake\"\n",
    ")\n",
    "\n",
    "dspy.configure(lm=qwen25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa48d79",
   "metadata": {},
   "source": [
    "Do look at the [dataset's HuggingFace page](https://huggingface.co/datasets/DigitalLearningGmbH/MATH-lighteval) for the full list of subsets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd357524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149fec833205467bb1a8142dcd1959e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "counting_and_probability/train-00000-of-(…):   0%|          | 0.00/329k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d39b6e8cb34c8c899080828111b26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "counting_and_probability/test-00000-of-0(…):   0%|          | 0.00/175k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c93e86dabd64cc2a21ce674c1bcdbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/771 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19dcc2c1fc734181a437d705a044a79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/474 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dspy.datasets import MATH\n",
    "\n",
    "dataset=MATH(subset='counting_and_probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86d7e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 158\n",
      "Question: One fair die has faces 1, 1, 2, 2, 3, 3 and another has faces 4, 4, 5, 5, 6, 6. The dice  are rolled and the numbers on the top faces are added. What is the probability that the sum will be odd?\n",
      "Answer: \\frac{5}{9}\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.train), len(dataset.dev))\n",
    "example = dataset.train[100]\n",
    "print(\"Question:\", example.question)\n",
    "print(\"Answer:\", example.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2ee8f",
   "metadata": {},
   "source": [
    "Defining the module and running an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea768e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"To determine the probability that the sum of the numbers on the top faces will be odd when rolling these two dice, we need to consider the parity (odd or even nature) of the outcomes.\\n\\n- The first die has three 1's and three 2's. Therefore, it can show an odd number with a probability of \\\\( \\\\frac{3}{6} = \\\\frac{1}{2} \\\\), and an even number with a probability of \\\\( \\\\frac{3}{6} = \\\\frac{1}{2} \\\\).\\n- The second die has three 4's and three 6's. Therefore, it can show an odd number with a probability of \\\\( \\\\frac{0}{6} = 0 \\\\), and an even number with a probability of \\\\( \\\\frac{6}{6} = 1 \\\\).\\n\\nFor the sum to be odd, one die must show an odd number and the other must show an even number. Since the second die always shows an even number, this means that the first die must show an odd number for their sum to be odd.\\n\\nThe probability of the first die showing an odd number is \\\\( \\\\frac{1}{2} \\\\).\\n\\nTherefore, the probability that the sum will be odd is \\\\( \\\\frac{1}{2} \\\\).\",\n",
       "    answer='\\\\(\\\\frac{1}{2}\\\\)'\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-087323f7f4d974646069ef2ddfe64675&amp;experiment_id=2&amp;version=3.2.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-087323f7f4d974646069ef2ddfe64675)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "module = dspy.ChainOfThought(\"question -> answer\")\n",
    "module(question=example.question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986db51",
   "metadata": {},
   "source": [
    "Setting up our evaluator and running it zero shot on our model!\n",
    "> This can take quite awhile. It took me close to 23 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f309d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.00 / 1 (0.0%):   1%|          | 1/158 [00:12<31:41, 12.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/math_equivalence.py:104: SyntaxWarning: invalid escape sequence '\\%'\n",
      "  string = string.replace(\"\\%\", \"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 158 (12.7%): 100%|██████████| 158/158 [22:57<00:00,  8.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 22:47:13 INFO dspy.evaluate.evaluate: Average Metric: 20 / 158 (12.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_reasoning</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>pred_reasoning</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Michael rolls three fair dice, what is the probability that he ...</td>\n",
       "      <td>We calculate the complement, or the probability that Michael does ...</td>\n",
       "      <td>\\frac{2}{27}</td>\n",
       "      <td>To find the probability that Michael will roll at least two 1's wh...</td>\n",
       "      <td>\\(\\frac{2}{27}\\)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In how many ways can 8 people sit around a round table if Pierre a...</td>\n",
       "      <td>Solution 1: We choose any seat for Pierre, and then seat everyone ...</td>\n",
       "      <td>960</td>\n",
       "      <td>To solve this problem, we need to consider several constraints: Pi...</td>\n",
       "      <td>1440</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compute $\\dbinom{7}{2}$.</td>\n",
       "      <td>$\\dbinom{7}{2}=\\dfrac{7\\times 6}{2}=\\boxed{21}.$</td>\n",
       "      <td>21</td>\n",
       "      <td>The binomial coefficient \\(\\binom{n}{k}\\) is calculated using the ...</td>\n",
       "      <td>21</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A team averages 7 losses for every 13 games it wins. If ties are n...</td>\n",
       "      <td>If a team averages 7 losses for 13 wins, that means the team wins ...</td>\n",
       "      <td>65\\%</td>\n",
       "      <td>To find the probability that the team will win its next game, we n...</td>\n",
       "      <td>65%</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I coach a soccer team with 15 members. I want to choose a starting...</td>\n",
       "      <td>There are $\\binom{15}{2}=105$ ways to select the 2 captains from a...</td>\n",
       "      <td>75,075</td>\n",
       "      <td>To solve this problem, we need to break it down into two parts: ch...</td>\n",
       "      <td>\\[ \\binom{15}{11} \\times \\binom{11}{2} = \\frac{15!}{11!4!} \\times ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                question  \\\n",
       "0  If Michael rolls three fair dice, what is the probability that he ...   \n",
       "1  In how many ways can 8 people sit around a round table if Pierre a...   \n",
       "2                                               Compute $\\dbinom{7}{2}$.   \n",
       "3  A team averages 7 losses for every 13 games it wins. If ties are n...   \n",
       "4  I coach a soccer team with 15 members. I want to choose a starting...   \n",
       "\n",
       "                                                       example_reasoning  \\\n",
       "0  We calculate the complement, or the probability that Michael does ...   \n",
       "1  Solution 1: We choose any seat for Pierre, and then seat everyone ...   \n",
       "2                       $\\dbinom{7}{2}=\\dfrac{7\\times 6}{2}=\\boxed{21}.$   \n",
       "3  If a team averages 7 losses for 13 wins, that means the team wins ...   \n",
       "4  There are $\\binom{15}{2}=105$ ways to select the 2 captains from a...   \n",
       "\n",
       "  example_answer  \\\n",
       "0   \\frac{2}{27}   \n",
       "1            960   \n",
       "2             21   \n",
       "3           65\\%   \n",
       "4         75,075   \n",
       "\n",
       "                                                          pred_reasoning  \\\n",
       "0  To find the probability that Michael will roll at least two 1's wh...   \n",
       "1  To solve this problem, we need to consider several constraints: Pi...   \n",
       "2  The binomial coefficient \\(\\binom{n}{k}\\) is calculated using the ...   \n",
       "3  To find the probability that the team will win its next game, we n...   \n",
       "4  To solve this problem, we need to break it down into two parts: ch...   \n",
       "\n",
       "                                                             pred_answer  \\\n",
       "0                                                       \\(\\frac{2}{27}\\)   \n",
       "1                                                                   1440   \n",
       "2                                                                     21   \n",
       "3                                                                    65%   \n",
       "4  \\[ \\binom{15}{11} \\times \\binom{11}{2} = \\frac{15!}{11!4!} \\times ...   \n",
       "\n",
       "      method  \n",
       "0             \n",
       "1             \n",
       "2  ✔️ [True]  \n",
       "3             \n",
       "4             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 153 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "12.66"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://127.0.0.1:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-d4cf364645702f2973a79f7c0d7f1c9e&amp;experiment_id=2&amp;trace_id=tr-94597ad1fd2d93d795c226032aa38711&amp;experiment_id=2&amp;trace_id=tr-038cd9ce898b1606c4bcd067b7c39fae&amp;experiment_id=2&amp;trace_id=tr-5e0341dcf5bb7f5869813925a78d7d44&amp;experiment_id=2&amp;trace_id=tr-f06916de5c6da245ffda11bf50e79679&amp;experiment_id=2&amp;trace_id=tr-47573907024d8f27d87a80260772f4ef&amp;experiment_id=2&amp;trace_id=tr-6e4c054fb6ac330cf0f48bf64e2ac503&amp;experiment_id=2&amp;trace_id=tr-0ce764acd8db96f8528eb880c2b15dd6&amp;experiment_id=2&amp;trace_id=tr-f32ecdf488dc4224e789bd5a9241b47c&amp;experiment_id=2&amp;trace_id=tr-0b58888f5d0d6e65329c5ab06624b370&amp;experiment_id=2&amp;version=3.2.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-d4cf364645702f2973a79f7c0d7f1c9e), Trace(trace_id=tr-94597ad1fd2d93d795c226032aa38711), Trace(trace_id=tr-038cd9ce898b1606c4bcd067b7c39fae), Trace(trace_id=tr-5e0341dcf5bb7f5869813925a78d7d44), Trace(trace_id=tr-f06916de5c6da245ffda11bf50e79679), Trace(trace_id=tr-47573907024d8f27d87a80260772f4ef), Trace(trace_id=tr-6e4c054fb6ac330cf0f48bf64e2ac503), Trace(trace_id=tr-0ce764acd8db96f8528eb880c2b15dd6), Trace(trace_id=tr-f32ecdf488dc4224e789bd5a9241b47c), Trace(trace_id=tr-0b58888f5d0d6e65329c5ab06624b370)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "THREADS = 24\n",
    "kwargs = dict(num_threads=THREADS, display_progress=True, display_table=5)\n",
    "evaluate = dspy.Evaluate(devset=dataset.dev, metric=dataset.metric, **kwargs)\n",
    "\n",
    "evaluate(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e28aa",
   "metadata": {},
   "source": [
    "Wow our model performed so badly - just 12.66%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64680a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(num_threads=THREADS, teacher_settings=dict(lm=lm), prompt_model=qwen25)\n",
    "optimizer = dspy.MIPROv2(metric=dataset.metric, auto=\"medium\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c9234d",
   "metadata": {},
   "source": [
    "This will take quite awhile! It took me more than an hour!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9da25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:25:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 24\n",
      "\n",
      "2025/08/13 12:25:36 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/08/13 12:25:36 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/08/13 12:25:36 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [01:55<00:57, 29.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:29:40 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "100%|██████████| 6/6 [02:46<00:00, 27.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:29<00:17, 17.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [03:02<01:31, 45.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:36:32 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "100%|██████████| 6/6 [02:45<00:00, 27.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 5 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:09<00:45,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:51<00:51, 17.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:40:22 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      " 50%|█████     | 3/6 [02:27<02:27, 49.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [02:15<00:27, 27.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:19<01:36, 19.27s/it]\n",
      "2025/08/13 12:43:39 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/08/13 12:43:39 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Error getting source code: unhashable type: 'dict'.\n",
      "\n",
      "Running without program aware proposer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:43:48 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a cybersecurity analyst tasked with ensuring the integrity of your company's data. A critical piece of information is that January 1, 2007 was a Monday. Your team needs to know how many Fridays there were in 2007 to verify an important log entry. Using only this fact and without writing any code, determine the number of Fridays in 2007.\n",
      "\n",
      "Failure to provide the correct answer could result in a significant security breach. Make your reasoning clear and concise.\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a math teacher preparing lesson plans for your class in 2007. Given that January 1, 2007 was a Monday, how many Fridays will there be in the year 2007?\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 3: You are a mathematician tasked with preparing for an international competition where you will face challenging mathematical problems under extreme time pressure. One of the problems presented is about finding the number of diagonals in complex polyhedra, such as a pentagonal prism. Given that the problem states: \"A diagonal of a polyhedron is a line segment connecting two non-adjacent vertices. How many diagonals does a pentagonal prism have?\" Can you quickly and accurately determine the answer to this question without making any mistakes?\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given a mathematical problem stated in `question`, provide the step-by-step reasoning process and the final answer in `answer`.\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Given a set of mathematical problems that involve reasoning, counting techniques, area calculations, or probability, your task is to provide a step-by-step solution that leads to an exact numerical answer. The questions will often require you to break down the problem into simpler parts and use logical steps to arrive at the final result. Ensure your response includes the reasoning process and the final answer expressed as a common fraction, integer, or other appropriate format.\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/08/13 12:44:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 18 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 24 (16.7%): 100%|██████████| 24/24 [00:51<00:00,  2.13s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:45:02 INFO dspy.evaluate.evaluate: Average Metric: 4 / 24 (16.7%)\n",
      "2025/08/13 12:45:02 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 16.67\n",
      "\n",
      "/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/08/13 12:45:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 3 (33.3%):  12%|█▎        | 3/24 [00:36<03:54, 11.16s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:47:05 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 21 (28.6%):  88%|████████▊ | 21/24 [04:55<00:22,  7.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:49:58 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [05:16<00:00, 13.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:50:19 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 29.17\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17]\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 29.17\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 12:50:19 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.00 / 24 (33.3%): 100%|██████████| 24/24 [06:49<00:00, 17.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:57:08 INFO dspy.evaluate.evaluate: Average Metric: 8 / 24 (33.3%)\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 33.33\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33]\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 12:57:08 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.00 / 12 (16.7%):  50%|█████     | 12/24 [02:35<01:32,  7.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:01:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 21 (28.6%):  88%|████████▊ | 21/24 [05:42<00:36, 12.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:02:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [06:29<00:00, 16.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:03:38 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:03:39 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 13:03:39 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17]\n",
      "2025/08/13 13:03:39 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/13 13:03:39 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:03:39 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [05:58<00:00, 14.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:09:37 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n",
      "2025/08/13 13:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/08/13 13:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17]\n",
      "2025/08/13 13:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/13 13:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:09:37 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [04:56<00:00, 12.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:14:33 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n",
      "2025/08/13 13:14:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/08/13 13:14:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17]\n",
      "2025/08/13 13:14:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/13 13:14:33 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:14:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 5 (20.0%):  21%|██        | 5/24 [01:35<04:27, 14.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:16:19 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.00 / 16 (25.0%):  67%|██████▋   | 16/24 [03:36<01:07,  8.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:19:55 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 21 (23.8%):  88%|████████▊ | 21/24 [06:10<00:48, 16.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:20:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/08/13 13:20:44 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [06:29<00:00, 16.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:21:03 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n",
      "2025/08/13 13:21:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 13:21:03 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17]\n",
      "2025/08/13 13:21:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 33.33\n",
      "2025/08/13 13:21:03 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:21:03 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 22 (54.5%):  92%|█████████▏| 22/24 [03:46<00:22, 11.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:26:16 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 23 (52.2%):  96%|█████████▌| 23/24 [05:22<00:36, 36.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:27:53 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 23 (52.2%): 100%|██████████| 24/24 [07:07<00:00, 57.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:28:10 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.00 / 24 (50.0%): : 27it [07:24, 16.48s/it]                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:28:28 INFO dspy.evaluate.evaluate: Average Metric: 12 / 24 (50.0%)\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mBest full score so far!\u001b[0m Score: 50.0\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0]\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:28:28 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 24 (25.0%): 100%|██████████| 24/24 [06:04<00:00, 15.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:34:33 INFO dspy.evaluate.evaluate: Average Metric: 6 / 24 (25.0%)\n",
      "2025/08/13 13:34:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/08/13 13:34:33 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0]\n",
      "2025/08/13 13:34:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:34:33 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/08/13 13:34:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 19 (21.1%):  79%|███████▉  | 19/24 [03:27<00:41,  8.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:39:26 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 21 (23.8%):  88%|████████▊ | 21/24 [05:13<01:22, 27.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:39:46 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 24 (25.0%): 100%|██████████| 24/24 [05:32<00:00, 13.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:40:05 INFO dspy.evaluate.evaluate: Average Metric: 6 / 24 (25.0%)\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0]\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 18 =====\n",
      "2025/08/13 13:40:05 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 24 (50.0%): 100%|██████████| 24/24 [00:00<00:00, 3625.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:40:05 INFO dspy.evaluate.evaluate: Average Metric: 12 / 24 (50.0%)\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0]\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 18 =====\n",
      "2025/08/13 13:40:05 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 24 (50.0%): 100%|██████████| 24/24 [00:00<00:00, 4541.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:40:05 INFO dspy.evaluate.evaluate: Average Metric: 12 / 24 (50.0%)\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 50.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0]\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:40:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 1 (100.0%):   4%|▍         | 1/24 [00:32<12:19, 32.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:42:05 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 21 (42.9%):  88%|████████▊ | 21/24 [05:24<00:39, 13.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:45:29 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 24 (37.5%): 100%|██████████| 24/24 [05:54<00:00, 14.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:45:59 INFO dspy.evaluate.evaluate: Average Metric: 9 / 24 (37.5%)\n",
      "2025/08/13 13:45:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 37.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/08/13 13:45:59 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5]\n",
      "2025/08/13 13:45:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:45:59 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:45:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.00 / 16 (43.8%):  67%|██████▋   | 16/24 [03:12<01:05,  8.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:50:57 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 21 (38.1%):  88%|████████▊ | 21/24 [05:51<00:56, 18.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:51:51 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.00 / 24 (33.3%): 100%|██████████| 24/24 [06:14<00:00, 15.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:52:14 INFO dspy.evaluate.evaluate: Average Metric: 8 / 24 (33.3%)\n",
      "2025/08/13 13:52:14 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 13:52:14 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33]\n",
      "2025/08/13 13:52:14 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:52:14 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:52:14 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.00 / 24 (37.5%): 100%|██████████| 24/24 [04:19<00:00, 10.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 13:56:34 INFO dspy.evaluate.evaluate: Average Metric: 9 / 24 (37.5%)\n",
      "2025/08/13 13:56:34 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 37.5 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 9'].\n",
      "2025/08/13 13:56:34 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33, 37.5]\n",
      "2025/08/13 13:56:34 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 13:56:34 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 13:56:34 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.00 / 17 (35.3%):  71%|███████   | 17/24 [02:58<01:02,  8.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:01:16 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 21 (42.9%):  88%|████████▊ | 21/24 [05:29<01:00, 20.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:02:03 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 24 (41.7%): 100%|██████████| 24/24 [05:48<00:00, 14.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:02:22 INFO dspy.evaluate.evaluate: Average Metric: 10 / 24 (41.7%)\n",
      "2025/08/13 14:02:22 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 41.67 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/08/13 14:02:22 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33, 37.5, 41.67]\n",
      "2025/08/13 14:02:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 14:02:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 14:02:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 9 (44.4%):  38%|███▊      | 9/24 [01:34<01:49,  7.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:05:01 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.00 / 21 (23.8%):  88%|████████▊ | 21/24 [05:31<00:42, 14.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:07:54 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.00 / 24 (25.0%): 100%|██████████| 24/24 [06:04<00:00, 15.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:08:27 INFO dspy.evaluate.evaluate: Average Metric: 6 / 24 (25.0%)\n",
      "2025/08/13 14:08:27 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.0 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/08/13 14:08:27 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33, 37.5, 41.67, 25.0]\n",
      "2025/08/13 14:08:27 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 14:08:27 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 14:08:27 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.00 / 24 (29.2%): 100%|██████████| 24/24 [05:05<00:00, 12.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:13:32 INFO dspy.evaluate.evaluate: Average Metric: 7 / 24 (29.2%)\n",
      "2025/08/13 14:13:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 29.17 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 14:13:32 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33, 37.5, 41.67, 25.0, 29.17]\n",
      "2025/08/13 14:13:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 14:13:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 14:13:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 18 =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.00 / 24 (33.3%): 100%|██████████| 24/24 [05:43<00:00, 14.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 14:19:15 INFO dspy.evaluate.evaluate: Average Metric: 8 / 24 (33.3%)\n",
      "2025/08/13 14:19:15 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 33.33 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 14:19:15 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [16.67, 29.17, 33.33, 29.17, 29.17, 29.17, 29.17, 50.0, 25.0, 25.0, 50.0, 50.0, 37.5, 33.33, 37.5, 41.67, 25.0, 29.17, 33.33]\n",
      "2025/08/13 14:19:15 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 50.0\n",
      "2025/08/13 14:19:15 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/08/13 14:19:15 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 50.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "selected_trainset = random.sample(dataset.train, 30)\n",
    "kwargs = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
    "optimized_module = optimizer.compile(\n",
    "    module, \n",
    "    trainset=selected_trainset, \n",
    "    requires_permission_to_run=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef31e7",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = dict(num_threads=THREADS, display_progress=True)\n",
    "evaluate = dspy.Evaluate(devset=dataset.dev, metric=dataset.metric, **kwargs)\n",
    "\n",
    "# Evaluate the program as usual\n",
    "result = evaluate(optimized_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afdd2657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.24"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73039b64",
   "metadata": {},
   "source": [
    "To save our optimized module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db35b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_module.save(\"../optimized_math_qwen25_7bn.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "519b16df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-13T14:49:47.136059]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given a set of mathematical problems that involve reasoning, counting techniques, area calculations, or probability, your task is to provide a step-by-step solution that leads to an exact numerical answer. The questions will often require you to break down the problem into simpler parts and use logical steps to arrive at the final result. Ensure your response includes the reasoning process and the final answer expressed as a common fraction, integer, or other appropriate format.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "What is the nearest integer to $(5+2\\sqrt7)^4$?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "When we expand this out, we get a bunch of terms with $\\sqrt7$ in them. To avoid painful estimation, we do the following trick: Add $(5-2\\sqrt7)^4$ to this expression. We know that $(5-2\\sqrt7)^4$ is small, since $2\\sqrt7=\\sqrt{28}$ is close to $5=\\sqrt{25}$, at least compared to $6=\\sqrt{36}$. When we add these together, the $\\sqrt7$ terms magically cancel out. By the Binomial Theorem, $$(5+2\\sqrt7)^4=5^4+4\\cdot5^3\\cdot(2\\sqrt7)+6\\cdot5^2\\cdot(2\\sqrt7)^2+4\\cdot5\\cdot(2\\sqrt7)^3+(2\\sqrt7)^4$$ whereas $$(5-2\\sqrt7)^4=5^4-4\\cdot5^3\\cdot(2\\sqrt7)+6\\cdot5^2\\cdot(2\\sqrt7)^2-4\\cdot5\\cdot(2\\sqrt7)^3+(2\\sqrt7)^4.$$ Therefore, their sum is $$2(5^4+6\\cdot5^2(2\\sqrt7)^2+(2\\sqrt7)^4)=2(625+4200+784)=11218.$$ Since the term we added, $(5-2\\sqrt7)^4$, is less than a half (actually, it's less than .01), $\\boxed{11218}$ is the closest integer to $(5+2\\sqrt7)^4$.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "11218\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Rectangle $ABCD$ has center $O$ and $AB/AD=k$. A point is randomly chosen from the interior of rectangle $ABCD$. What is the probability that it is closer to $O$ than to any of the four vertices?  [asy]\n",
      "size(200);\n",
      "draw((-250,100)--(250,100)--(250,-100)--(-250,-100)--cycle);\n",
      "dot((0,0));\n",
      "label(\"$O$\",(0,0),N);\n",
      "label(\"$A$\",(-250,100),NW); label(\"$B$\",(250,100),NE); label(\"$C$\",(250,-100),SE); label(\"$D$\",(-250,-100),SW);[/asy]\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The original rectangle may be subdivided into four smaller congruent rectangles, all sharing $O$ as a vertex. Each of these rectangles is analogous, so we can consider our random point $P$ to be without loss of generality in the smaller rectangle with $A$ as a vertex. All points in this smaller rectangle are closer to $A$ than they are to $B$, $C$, or $D$, so we just need to determine the probability that $OP<AP$. [asy]\n",
      "size(100);\n",
      "draw((0,0)--(0,100)--(-250,100)--(-250,0)--cycle);\n",
      "label(\"$A$\",(-250,100),NW); label(\"$O$\",(0,0),SE);\n",
      "draw((-105,100)--(-145,0));\n",
      "fill((-105,100)--(-145,0)--(0,0)--(0,100)--cycle, gray(.7));\n",
      "[/asy] Since a $180^\\circ$ rotation about the center of the smaller rectangle takes $O$ to $A$, it takes the shaded region to the unshaded region. Therefore, exactly half the area is shaded, and the overall probability is $\\boxed{\\frac{1}{2}}$, independent of $k$.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "\\frac{1}{2}\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "A diagonal of a polyhedron is a line segment connecting two non-adjacent vertices. How many diagonals does a pentagonal prism have? [asy]\n",
      "import three;\n",
      "size(100);\n",
      "defaultpen(linewidth(0.7));\n",
      "currentprojection = orthographic(-0.2,-1,2/3);\n",
      "\n",
      "void drawPentagon (real h)\n",
      "{\n",
      "\n",
      "path3 y;\n",
      "\n",
      "y=(0,0,h)--(3,0,h)--(5,3,h)--(3,6,h)--(0,5,h)--cycle;\n",
      "\n",
      "draw(surface(y),white,nolight);\n",
      "\n",
      "draw(y);\n",
      "}\n",
      "\n",
      "void drawRectangle(triple a, triple b, real h)\n",
      "{\n",
      "\n",
      "path3 y;\n",
      "\n",
      "y=a--b--b+(0,0,h)--a+(0,0,h)--cycle;\n",
      "\n",
      "draw(surface(y),white,black,nolight);\n",
      "}\n",
      "\n",
      "drawRectangle((0,0,0),(0,5,0),4);\n",
      "drawRectangle((0,0,0),(3,0,0),4);\n",
      "drawRectangle((3,0,0),(5,3,0),4);\n",
      "drawPentagon(4);\n",
      "\n",
      "//import three; currentprojection = orthographic(25,150,100); //defaultpen(linewidth(0.8)); size(100);\n",
      "//void nGon(int numSides, real height){\n",
      "//real angle = 360/numSides;\n",
      "//for(int i = 0; i < numSides; ++i){\n",
      "//draw(dir(angle*i,0)--dir(angle*(i + 1),0));\n",
      "//draw((dir(angle*i,0) + (0,0,height))--(dir(angle*(i + 1),0) + (0,0,height)));\n",
      "//draw(dir(angle*i,0)--(dir(angle*i,0) + (0,0,height)));\n",
      "// }\n",
      "//}\n",
      "//nGon(5,2);\n",
      "[/asy]\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "There are $5+5+5=15$ edges, so among the $\\binom{10}{2}=45$ pairs of vertices, $15$ of them are adjacent.  The other $45-15=\\boxed{30}$ pairs correspond to diagonals.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "30\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Steve has one quarter, two nickels and three pennies. Assuming no items are free, for how many different-priced items could Steve individually pay for with exact change?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Steve can use no quarters or one quarter, for two possibilities.\n",
      "\n",
      "Steve can use 0, 1, or 2 nickels, for three possibilities.\n",
      "\n",
      "And Steve can use 0, 1, 2, or 3 pennies, for four possibilities.  That gives $2 \\cdot 3 \\cdot 4 = 24$ possible combinations.  But we must remove the combination where Steve does not use any coins, leaving us with $24 - 1 = \\boxed{23}.$\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "23\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "On the student government ballot at Dusable High School, the six candidates for president are listed first, followed by the four candidates for vice president, followed by the five candidates for secretary and ending with the three candidates for treasurer. In how many ways can the candidates be listed on the ballot?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To determine the number of ways to list the candidates on the ballot, we need to consider each position separately. The six candidates for president can be listed in any order among themselves, which gives us \\(6!\\) (6 factorial) permutations. Similarly, the four candidates for vice president can be listed in \\(4!\\) different orders, and the five candidates for secretary in \\(5!\\) different orders, and the three candidates for treasurer in \\(3!\\) different orders.\n",
      "\n",
      "The total number of ways to list all the candidates is the product of these individual permutations. Therefore, we calculate:\n",
      "\n",
      "\\[6! \\times 4! \\times 5! \\times 3!\\]\n",
      "\n",
      "Calculating each factorial:\n",
      "- \\(6! = 720\\)\n",
      "- \\(4! = 24\\)\n",
      "- \\(5! = 120\\)\n",
      "- \\(3! = 6\\)\n",
      "\n",
      "Multiplying these together gives:\n",
      "\n",
      "\\[720 \\times 24 \\times 120 \\times 6\\]\n",
      "\n",
      "First, we can simplify the multiplication step-by-step:\n",
      "\\[720 \\times 24 = 17280\\]\n",
      "\\[17280 \\times 120 = 2073600\\]\n",
      "\\[2073600 \\times 6 = 12441600\\]\n",
      "\n",
      "Thus, the total number of ways to list the candidates on the ballot is \\(12441600\\).\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "12441600\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913acb19",
   "metadata": {},
   "source": [
    "Running the full set takes too long - it was 3hrs and it still wasn't halfway done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64bbb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 09:24:05 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: True\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mProjected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Prompt Generation: \u001b[94m\u001b[1m10\u001b[0m\u001b[93m data summarizer calls + \u001b[94m\u001b[1m6\u001b[0m\u001b[93m * \u001b[94m\u001b[1m1\u001b[0m\u001b[93m lm calls in program + (\u001b[94m\u001b[1m2\u001b[0m\u001b[93m) lm calls in program-aware proposer = \u001b[94m\u001b[1m18\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\u001b[93m- Program Evaluation: \u001b[94m\u001b[1m35\u001b[0m\u001b[93m examples in minibatch * \u001b[94m\u001b[1m18\u001b[0m\u001b[93m batches + \u001b[94m\u001b[1m126\u001b[0m\u001b[93m examples in val set * \u001b[94m\u001b[1m4\u001b[0m\u001b[93m full evals = \u001b[94m\u001b[1m1134\u001b[0m\u001b[93m LM Program calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token)\n",
      "            + (Number of program calls * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the valset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "\u001b[93m- Setting `minibatch=True` if you haven't already.\u001b[0m\n",
      "\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "If no input is received within 20 seconds, the program will proceed automatically.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`\u001b[0m when calling compile.\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n",
      "Do you wish to continue? (y/n): "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 09:24:25 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/08/13 09:24:25 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/08/13 09:24:25 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No input received within 20 seconds. Proceeding with execution...\n",
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 7/32 [03:20<11:54, 28.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples for up to 1 rounds, amounting to 7 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:49<07:56, 16.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [01:02<10:07, 20.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [01:03<07:21, 15.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [00:45<07:23, 15.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:13<06:46, 13.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 4/32 [01:15<08:48, 18.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:08<04:12,  8.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:34<17:34, 34.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 3/32 [01:00<09:48, 20.29s/it]\n",
      "2025/08/13 09:34:38 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/08/13 09:34:38 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Error getting source code: unhashable type: 'dict'.\n",
      "\n",
      "Running without program aware proposer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 09:35:13 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 1: apples (A), bananas (B), grapes (G), strawberries (S), and pineapples (P). Some combinations do not taste good together - specifically, strawberries and pineapples should not be in the same fruit salad, and grapes and bananas should not be used together. How many different fruit salads can you make using any 3 of these fruits without violating the taste or appearance rules?\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a problem involving probability, combinatorics, or basic statistics presented as a real-world scenario, compute the answer step-by-step by identifying key elements of the question, applying relevant mathematical principles, and providing a clear explanation.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given a problem statement that involves counting or probability, provide the answer by first breaking down the problem into steps and explaining your reasoning. For example, if asked about subsets of divisors containing only composite numbers, list all relevant divisors, identify which are composite, and then calculate the number of possible subsets.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 4: You are an educator preparing materials to help students understand probability problems in real-world scenarios. Use the information from the provided dataset description and the example question to create a new problem that involves calculating probabilities using combinatorics, ensuring it's different from the given examples.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Given a word or phrase, determine the number of distinct ways to arrange its letters. For example, in the word \"TEPEE\", we have 5 letters where 'E' appears three times and 'T', 'P' each appear once. Please provide your answer as an integer representing the total number of unique arrangements.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/08/13 09:35:38 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 23 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 126 (11.1%): 100%|██████████| 126/126 [18:08<00:00,  8.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 09:53:47 INFO dspy.evaluate.evaluate: Average Metric: 14 / 126 (11.1%)\n",
      "2025/08/13 09:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 11.11\n",
      "\n",
      "/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/08/13 09:53:47 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.00 / 35 (25.7%): 100%|██████████| 35/35 [05:36<00:00,  9.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 09:59:23 INFO dspy.evaluate.evaluate: Average Metric: 9 / 35 (25.7%)\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71]\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11]\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 11.11\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 09:59:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.00 / 35 (40.0%): 100%|██████████| 35/35 [07:48<00:00, 13.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:07:11 INFO dspy.evaluate.evaluate: Average Metric: 14 / 35 (40.0%)\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0]\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11]\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 11.11\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:07:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 35 (34.3%): 100%|██████████| 35/35 [05:21<00:00,  9.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:12:33 INFO dspy.evaluate.evaluate: Average Metric: 12 / 35 (34.3%)\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 34.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29]\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11]\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 11.11\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:12:33 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.00 / 35 (25.7%): 100%|██████████| 35/35 [06:33<00:00, 11.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:19:07 INFO dspy.evaluate.evaluate: Average Metric: 9 / 35 (25.7%)\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71]\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11]\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 11.11\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:19:07 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 35 (34.3%): 100%|██████████| 35/35 [05:28<00:00,  9.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:24:36 INFO dspy.evaluate.evaluate: Average Metric: 12 / 35 (34.3%)\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 34.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29]\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11]\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 11.11\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 23 - Full Evaluation =====\n",
      "2025/08/13 10:24:36 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 40.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.00 / 126 (34.9%): 100%|██████████| 126/126 [14:35<00:00,  6.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:39:11 INFO dspy.evaluate.evaluate: Average Metric: 44 / 126 (34.9%)\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 34.92\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/08/13 10:39:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.00 / 35 (34.3%): 100%|██████████| 35/35 [06:04<00:00, 10.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:45:16 INFO dspy.evaluate.evaluate: Average Metric: 12 / 35 (34.3%)\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 34.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29, 34.29]\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:45:16 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.00 / 5 (20.0%):  14%|█▍        | 5/35 [01:16<06:00, 12.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:48:20 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.00 / 32 (28.1%):  91%|█████████▏| 32/35 [08:47<00:59, 19.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:54:04 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.00 / 35 (28.6%): 100%|██████████| 35/35 [09:04<00:00, 15.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:54:21 INFO dspy.evaluate.evaluate: Average Metric: 10 / 35 (28.6%)\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 28.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29, 34.29, 28.57]\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/08/13 10:54:21 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.00 / 2 (100.0%):   6%|▌         | 2/35 [00:28<06:50, 12.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 10:56:25 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.00 / 35 (40.0%): 100%|██████████| 35/35 [07:20<00:00, 12.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 11:01:41 INFO dspy.evaluate.evaluate: Average Metric: 14 / 35 (40.0%)\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 40.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29, 34.29, 28.57, 40.0]\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.00 / 35 (25.7%): 100%|██████████| 35/35 [00:00<00:00, 3971.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 11:01:41 INFO dspy.evaluate.evaluate: Average Metric: 9 / 35 (25.7%)\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 25.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29, 34.29, 28.57, 40.0, 25.71]\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/08/13 11:01:41 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.00 / 35 (31.4%): 100%|██████████| 35/35 [04:35<00:00,  7.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 11:06:17 INFO dspy.evaluate.evaluate: Average Metric: 11 / 35 (31.4%)\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 31.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [25.71, 40.0, 34.29, 25.71, 34.29, 34.29, 28.57, 40.0, 25.71, 31.43]\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [11.11, 34.92]\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 34.92\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 23 - Full Evaluation =====\n",
      "2025/08/13 11:06:17 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 35.715) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.00 / 21 (19.0%):  17%|█▋        | 21/126 [01:14<06:57,  3.98s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 11:07:31 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 120 (30.0%):  95%|█████████▌| 120/126 [1:15:53<04:29, 44.85s/it]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/13 12:22:15 WARNING dspy.utils.parallelizer: SIGINT received. Cancelling.\n",
      "[W 2025-08-13 12:22:15,643] Trial 11 failed with parameters: {'0_predictor_instruction': 3, '0_predictor_demos': 3} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py\", line 614, in objective\n",
      "    best_score, best_program, total_eval_calls = self._perform_full_evaluation(\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py\", line 798, in _perform_full_evaluation\n",
      "    full_eval_score = eval_candidate_program(len(valset), valset, highest_mean_program, evaluate, self.rng)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/utils.py\", line 52, in eval_candidate_program\n",
      "    return evaluate(candidate_program, devset=trainset, return_all_scores=return_all_scores, callback_metadata={\"metric_key\": \"eval_full\"})\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 483, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/dspy/autolog.py\", line 140, in patch_fn\n",
      "    return original(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 474, in call_original\n",
      "    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 425, in call_original_fn_with_event_logging\n",
      "    original_fn_result = original_fn(*og_args, **og_kwargs)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py\", line 471, in _original_fn\n",
      "    original_result = original(*_og_args, **_og_kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 339, in sync_wrapper\n",
      "    results = fn(instance, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/evaluate/evaluate.py\", line 171, in __call__\n",
      "    results = executor.execute(process_item, devset)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 48, in execute\n",
      "    return self._execute_parallel(wrapped, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 149, in _execute_parallel\n",
      "    done, not_done = wait(futures_set, timeout=1, return_when=FIRST_COMPLETED)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llamaindex/lib/python3.12/concurrent/futures/_base.py\", line 305, in wait\n",
      "    waiter.event.wait(timeout)\n",
      "  File \"/opt/anaconda3/envs/llamaindex/lib/python3.12/threading.py\", line 655, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/llamaindex/lib/python3.12/threading.py\", line 359, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/tituslim/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 109, in handler\n",
      "    orig_handler(sig, frame)\n",
      "KeyboardInterrupt\n",
      "[W 2025-08-13 12:22:15,651] Trial 11 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(max_bootstrapped_demos=\u001b[32m4\u001b[39m, max_labeled_demos=\u001b[32m4\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m optimized_module = \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    481\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/dspy/autolog.py:105\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Teleprompter):\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m get_autologging_config(FLAVOR_NAME, \u001b[33m\"\u001b[39m\u001b[33mlog_compiles\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     program = _compile_fn(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# Save the state of the best model in json format\u001b[39;00m\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# so that users can see the demonstrations and instructions.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/dspy/autolog.py:94\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn.<locals>._compile_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m         result = original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         result = \u001b[43m_trace_disabled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/tracing/provider.py:465\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    464\u001b[39m     is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    467\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/dspy/autolog.py:85\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn.<locals>._trace_disabled_fn\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;129m@trace_disabled\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_trace_disabled_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    423\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    468\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    469\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:204\u001b[39m, in \u001b[36mMIPROv2.compile\u001b[39m\u001b[34m(self, student, trainset, teacher, valset, num_trials, max_bootstrapped_demos, max_labeled_demos, seed, minibatch, minibatch_size, minibatch_full_eval_steps, program_aware_proposer, data_aware_proposer, view_data_batch_size, tip_aware_proposer, fewshot_aware_proposer, requires_permission_to_run, provide_traceback)\u001b[39m\n\u001b[32m    201\u001b[39m     demo_candidates = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Step 3: Find optimal prompt parameters\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m best_program = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimize_prompt_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstruction_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminibatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mminibatch_full_eval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m best_program\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:647\u001b[39m, in \u001b[36mMIPROv2._optimize_prompt_parameters\u001b[39m\u001b[34m(self, program, instruction_candidates, demo_candidates, evaluate, valset, num_trials, minibatch, minibatch_size, minibatch_full_eval_steps, seed)\u001b[39m\n\u001b[32m    641\u001b[39m trial = optuna.trial.create_trial(\n\u001b[32m    642\u001b[39m     params=default_params,\n\u001b[32m    643\u001b[39m     distributions=\u001b[38;5;28mself\u001b[39m._get_param_distributions(program, instruction_candidates, demo_candidates),\n\u001b[32m    644\u001b[39m     value=default_score,\n\u001b[32m    645\u001b[39m )\n\u001b[32m    646\u001b[39m study.add_trial(trial)\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;66;03m# Attach logs to best program\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_program \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_stats:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:614\u001b[39m, in \u001b[36mMIPROv2._optimize_prompt_parameters.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;66;03m# If minibatch, perform full evaluation at intervals (and at the very end)\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m minibatch \u001b[38;5;129;01mand\u001b[39;00m ((trial_num % (minibatch_full_eval_steps+\u001b[32m1\u001b[39m) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (trial_num == (adjusted_num_trials-\u001b[32m1\u001b[39m))):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     best_score, best_program, total_eval_calls = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_full_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43madjusted_num_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparam_score_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfully_evaled_param_combos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_eval_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbest_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbest_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstruction_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/mipro_optimizer_v2.py:798\u001b[39m, in \u001b[36mMIPROv2._perform_full_evaluation\u001b[39m\u001b[34m(self, trial_num, adjusted_num_trials, param_score_dict, fully_evaled_param_combos, evaluate, valset, trial_logs, total_eval_calls, score_data, best_score, best_program, study, instruction_candidates, demo_candidates)\u001b[39m\n\u001b[32m    794\u001b[39m highest_mean_program, mean_score, combo_key, params = get_program_with_highest_avg_score(\n\u001b[32m    795\u001b[39m     param_score_dict, fully_evaled_param_combos\n\u001b[32m    796\u001b[39m )\n\u001b[32m    797\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDoing full eval on next top averaging program (Avg Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) from minibatch trials...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m full_eval_score = \u001b[43meval_candidate_program\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhighest_mean_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m score_data.append({\u001b[33m\"\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m\"\u001b[39m: full_eval_score, \u001b[33m\"\u001b[39m\u001b[33mprogram\u001b[39m\u001b[33m\"\u001b[39m: highest_mean_program, \u001b[33m\"\u001b[39m\u001b[33mfull_eval\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Log full eval as a trial so that optuna can learn from the new results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/teleprompt/utils.py:52\u001b[39m, in \u001b[36meval_candidate_program\u001b[39m\u001b[34m(batch_size, trainset, candidate_program, evaluate, rng, return_all_scores)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# Evaluate on the full trainset\u001b[39;00m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch_size >= \u001b[38;5;28mlen\u001b[39m(trainset):\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_all_scores\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_all_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetric_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_full\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Or evaluate on a minibatch\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     55\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m evaluate(\n\u001b[32m     56\u001b[39m             candidate_program,\n\u001b[32m     57\u001b[39m             devset=create_minibatch(trainset, batch_size, rng),\n\u001b[32m     58\u001b[39m             return_all_scores=return_all_scores,\n\u001b[32m     59\u001b[39m             callback_metadata={\u001b[33m\"\u001b[39m\u001b[33mmetric_key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33meval_minibatch\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     60\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:483\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m call_original = update_wrapper_extended(call_original, original)\n\u001b[32m    481\u001b[39m event_logger.log_patch_function_start(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m session.state = \u001b[33m\"\u001b[39m\u001b[33msucceeded\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m event_logger.log_patch_function_success(args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/dspy/autolog.py:140\u001b[39m, in \u001b[36mautolog.<locals>.patch_fn\u001b[39m\u001b[34m(original, self, *args, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Evaluate) \u001b[38;5;129;01mand\u001b[39;00m get_autologging_config(\n\u001b[32m    138\u001b[39m     FLAVOR_NAME, \u001b[33m\"\u001b[39m\u001b[33mlog_traces_from_eval\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _trace_disabled_fn(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:474\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[39m\u001b[34m(*og_args, **og_kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m         original_result = original(*_og_args, **_og_kwargs)\n\u001b[32m    472\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:425\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[39m\u001b[34m(original_fn, og_args, og_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    423\u001b[39m     event_logger.log_original_function_start(og_args, og_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     original_fn_result = \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    427\u001b[39m     event_logger.log_original_function_success(og_args, og_kwargs)\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[39m, in \u001b[36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[39m\u001b[34m(*_og_args, **_og_kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m NonMlflowWarningsBehaviorForCurrentThread(\n\u001b[32m    468\u001b[39m     disable_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    469\u001b[39m     reroute_warnings=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     original_result = \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/callback.py:339\u001b[39m, in \u001b[36mwith_callbacks.<locals>.sync_wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    337\u001b[39m exception = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     results = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/evaluate/evaluate.py:171\u001b[39m, in \u001b[36mEvaluate.__call__\u001b[39m\u001b[34m(self, program, metric, devset, num_threads, display_progress, display_table, return_all_scores, return_outputs, callback_metadata)\u001b[39m\n\u001b[32m    167\u001b[39m         program._suggest_failures += dspy.settings.get(\u001b[33m\"\u001b[39m\u001b[33msuggest_failures\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction, score\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(devset) == \u001b[38;5;28mlen\u001b[39m(results)\n\u001b[32m    174\u001b[39m results = [((dspy.Prediction(), \u001b[38;5;28mself\u001b[39m.failure_score) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py:48\u001b[39m, in \u001b[36mParallelExecutor.execute\u001b[39m\u001b[34m(self, function, data)\u001b[39m\n\u001b[32m     46\u001b[39m tqdm.tqdm._instances.clear()\n\u001b[32m     47\u001b[39m wrapped = \u001b[38;5;28mself\u001b[39m._wrap_function(function)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py:149\u001b[39m, in \u001b[36mParallelExecutor._execute_parallel\u001b[39m\u001b[34m(self, function, data)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_done():\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m done, not_done = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m done:\n\u001b[32m    151\u001b[39m     futures_set.remove(f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llamaindex/lib/python3.12/concurrent/futures/_base.py:305\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[32m    303\u001b[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m f._condition:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llamaindex/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/llamaindex/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal Learning Folder/Personal Projects/dspy-playground/.venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py:109\u001b[39m, in \u001b[36mParallelExecutor._execute_parallel.<locals>.interrupt_manager.<locals>.handler\u001b[39m\u001b[34m(sig, frame)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mself\u001b[39m.cancel_jobs.set()\n\u001b[32m    108\u001b[39m logger.warning(\u001b[33m\"\u001b[39m\u001b[33mSIGINT received. Cancelling.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43morig_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimized_module = optimizer.compile(module, trainset=dataset.train, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33dc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
