{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc91ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8717141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"ollama_chat/gpt-oss:20b\", api_base=\"http://localhost:11434\", api_key=\"fake\")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae7516",
   "metadata": {},
   "source": [
    "To invoke the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb49a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"There are **3** 'r's in the word *strawberry*.\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(messages=[{\"role\": \"user\", \"content\": \"Hi! How many 'r's are there in strawberry?\"}])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbcfcb",
   "metadata": {},
   "source": [
    "# 1. Inline signatures\n",
    "\n",
    "Declare signatures inline using strings and arrows!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4231db3",
   "metadata": {},
   "source": [
    "## Chain Of Thought\n",
    "GPT-oss has a 128k context window! Let's make it summarize some documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1780c3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"../docs\"):\n",
    "    os.makedirs(\"../docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b65dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-08 21:52:57--  https://arxiv.org/pdf/2505.20286\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.3.42, 151.101.195.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.3.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1113373 (1.1M) [application/pdf]\n",
      "Saving to: ‘../docs/alita_paper.pdf’\n",
      "\n",
      "../docs/alita_paper 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-08-08 21:52:57 (24.0 MB/s) - ‘../docs/alita_paper.pdf’ saved [1113373/1113373]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://arxiv.org/pdf/2505.20286 -O \"../docs/alita_paper.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84ea038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "docs = SimpleDirectoryReader(\"../docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9981cc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Doc ID: 1fa1e383-cfb8-4b11-b488-2e3960d1e606\n",
       "Text: arXiv:2505.20286v1  [cs.AI]  26 May 2025 ALITA : G ENERALIST\n",
       "AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION\n",
       "AND MAXIMAL SELF -EVOLUTION Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng\n",
       "Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin\n",
       "Yao1, Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1,\n",
       "Yue Wu1, Kaixua..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(str(docs[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50f5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\n",
    "for doc in docs:\n",
    "    document += str(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e89b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize = dspy.ChainOfThought('document -> summary')\n",
    "response = summarize(document = document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a6e435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The paper “ALITA: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self‑Evolution” presents a lightweight, generalist agent framework that achieves strong performance on complex reasoning tasks without relying on extensive handcrafted tools or workflows. ALITA’s core idea is a manager agent that orchestrates a small set of powerful tools—MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool—while generating Meta‑Cognitive Plans (MCPs) on the fly to fill functional gaps. The system emphasizes isolated, reproducible execution environments and automatic recovery from failures. Evaluated on the GAIA benchmark, ALITA outperforms many existing agents, achieving 75.15 % pass@1 and 87.27 % pass@3 with Claude‑Sonnet‑4 and GPT‑4o. Performance tables show consistent gains across difficulty levels, and experiments demonstrate that reusing ALITA‑generated MCPs benefits other frameworks. The work highlights how minimal predefinition combined with self‑evolution can enable scalable, autonomous reasoning in large language model agents."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7681a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The input consists of a series of document fragments identified by unique IDs. All fragments relate to a single research paper titled “ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF‑EVOLUTION.” The fragments include the title, author list, abstract, introduction, method description, tool usage, experimental results, performance tables, and references. By scanning the text we can identify the key components of the paper:\n",
       "\n",
       "1. **Purpose and Motivation** – The paper addresses the need for generalist agents that can perform complex tasks without heavy pre‑engineering of tools or workflows, citing the rapid evolution of LLMs into autonomous agents.\n",
       "\n",
       "2. **Proposed Solution (ALITA)** – A minimal‑predefinition, maximal‑self‑evolution framework. It uses a manager agent that orchestrates a small set of powerful tools (MCP Brainstorming, ScriptGeneratingTool, CodeRunningTool) and relies on self‑generated “MCPs” (Meta‑Cognitive Plans) to fill functional gaps.\n",
       "\n",
       "3. **Methodology** – The manager agent dynamically selects tools, generates code, runs it in isolated environments, and iteratively refines plans. The system emphasizes isolation, reproducibility, and automatic recovery from failures.\n",
       "\n",
       "4. **Experimental Evaluation** – ALITA is evaluated on the GAIA benchmark. Results show superior performance compared to other agents, achieving 75.15 % pass@1 and 87.27 % pass@3 with Claude‑Sonnet‑4 and GPT‑4o. Tables compare performance across difficulty levels and against GPT‑4o‑mini.\n",
       "\n",
       "5. **Additional Findings** – Reuse of ALITA‑generated MCPs improves performance for other frameworks (Open Deep Research‑smolagents). The paper also discusses tool usage, environment activation, and failure handling.\n",
       "\n",
       "6. **Contextual Details** – The document includes author affiliations, references to related work, and a brief case study example.\n",
       "\n",
       "From these observations, a concise summary can be constructed that captures the motivation, design, key innovations, and empirical results of the ALITA system."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.reasoning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c245e438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-08T22:42:07.848670]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `document` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `summary` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## document ## ]]\n",
      "{document}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## summary ## ]]\n",
      "{summary}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `document`, produce the fields `summary`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## document ## ]]\n",
      "Doc ID: 1fa1e383-cfb8-4b11-b488-2e3960d1e606\n",
      "Text: arXiv:2505.20286v1  [cs.AI]  26 May 2025 ALITA : G ENERALIST\n",
      "AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION\n",
      "AND MAXIMAL SELF -EVOLUTION Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng\n",
      "Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin\n",
      "Yao1, Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1,\n",
      "Yue Wu1, Kaixua...Doc ID: 6d081601-b426-4a8d-bbfb-925213b9487a\n",
      "Text: 1 Introduction \"Simplicity is the ultimate sophistication.\" —\n",
      "Leonardo da Vinci Large language models (LLMs) have rapidly evolved\n",
      "from merely generating text to autonomous agents capable of\n",
      "independently planning and executing complex tasks on behalf of users\n",
      "with limited human oversight [ 2]. These capabilities have enabled a\n",
      "wide range of appl...Doc ID: 8960419c-a737-4468-9de1-342154f6a6ad\n",
      "Text: • We present Alita, a generalist agent that achieves scalable\n",
      "agentic reasoning with a radically simple design. • We empirically\n",
      "demonstrate that Alita, despite using no complex predefined tools and\n",
      "workflows for specific tasks, outperforms many systems with\n",
      "significantly more handcrafted complexity on the GAIA benchmark. We\n",
      "achieve 75.15% pass@...Doc ID: ac1914a6-c96e-4497-b9d4-f3b87a47d114\n",
      "Text: 3 Methods We propose Alita, a generalist agent enabling scalable\n",
      "agentic reasoning with minimal predefinition and maximal self-\n",
      "evolution to tackle diverse and complex tasks. Figure 3 illustrates\n",
      "the framework of Alita. In contrast to generalist agents that\n",
      "typically depend on extensive manually-designed tools and workflows\n",
      "[8, 9], the manager ag...Doc ID: 37d7be38-4ee8-49bc-a33f-09149bccc94d\n",
      "Text: Tool Usage. In contrast to traditional systems that rely on\n",
      "extensive predefined toolkits, the manager agent em- braces Alita’s\n",
      "minimal philosophy by employing concise but powerful toolkits,\n",
      "including MCP Brainstorming, ScriptGeneratingTool and CodeRunningTool.\n",
      "Specifically, MCP Brainstorming detects functional gaps, identi- fies\n",
      "necessary suppl...Doc ID: 85ff2aa7-f99f-4889-a601-43a67528dded\n",
      "Text: of the system. During execution, the environment is explicitly\n",
      "activated prior to invoking the code interpreter, thus ensuring both\n",
      "isolation and reproducibility. In the event of a failure during\n",
      "environment initialization—due to issues such as missing packages,\n",
      "syntax errors in setup scripts, or unavailable dependencies—Alita\n",
      "activates an autom...Doc ID: 79d6f9bd-bd4f-400e-aea4-37b5e417e276\n",
      "Text: framework excels in generating comprehensive reports on complex\n",
      "topics and has shown superior performance on benchmarks. 4.2 Results\n",
      "We run three rounds of testing on GAIA and achieved the best\n",
      "performance on the GAIA leaderboard, surpassing other agent systems.\n",
      "Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and\n",
      "87.27% pass@3 accur...Doc ID: bdba7133-079f-4f6d-a4a4-de1b206e8fc0\n",
      "Text: 5.1.2 Reuse by Open Deep Research-smolagents We run open Deep\n",
      "Research-smolagents [25] on GAIA with and without Alita-generated MCPs\n",
      "based on GPT-4o. The results are presented in Table 2. From this\n",
      "experiment, we observe that the reuse of Alita-generated MCPs results\n",
      "in better performance compared to the base framework for all\n",
      "difficulty levels....Doc ID: 30336fbe-8713-4af7-835f-7d2f2051fcae\n",
      "Text: Model Configuration Level 1 Level 2 Level 3 Total Alita\n",
      "(Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% 72.73% Alita\n",
      "(GPT-4o-mini) 54.72% 44.19% 19.23% 43.64% Table 4: Comparison of\n",
      "performance between Alita(Claude-3.7-Sonnet,GPT-4o) and\n",
      "Alita(GPT-4o-mini). The results are reported at different GAIA levels:\n",
      "Level 1, Level 2, Level 3, and the av...Doc ID: a416bc55-63b7-4a4a-940b-b7fcde54f691\n",
      "Text: References [1] OpenAI. Introducing deep research. [2] Noam Kolt.\n",
      "Governing ai agents. arXiv preprint arXiv:2501.07913, 2025. [3] Jian\n",
      "Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian,\n",
      "Yanghua Xiao, and Yu Su. Travelplanner: A benchmark for real-world\n",
      "planning with language agents. arXiv preprint arXiv:2402.01622, 2024.\n",
      "[4] Ti...Doc ID: 65087bdd-69ec-4321-9308-ff198fa94635\n",
      "Text: [21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt\n",
      "bloat in llm tool selection via retrieval-augmented generation. arXiv\n",
      "preprint arXiv:2505.03275, 2025. [22] Fengfei Sun, Ningke Li, Kailong\n",
      "Wang, and Lorenz Goette. Large language models are overconfident and\n",
      "amplify human bias. 2025. [23] Pan Lu, Hritik Bansal, Tony Xia,\n",
      "Jiacheng Liu, ...Doc ID: 7e077f04-2c4c-4b21-bcf4-429895c7b41b\n",
      "Text: A Detailed Case Study Case Study: YouTube 360 VR Video Subtitle\n",
      "Extraction Question ID: 0512426f-4d28-49f0-be77-06d05daec096 Question:\n",
      "In the YouTube 360 VR video from March 2018 narrated by the voice\n",
      "actor of Lord of the Rings’ Gollum, what number was mentioned by the\n",
      "narrator directly after dinosaurs were first shown in the video? Our\n",
      "Answer: ...\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## summary ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The input consists of a series of document fragments identified by unique IDs. All fragments relate to a single research paper titled “ALITA: GENERALIST AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION AND MAXIMAL SELF‑EVOLUTION.” The fragments include the title, author list, abstract, introduction, method description, tool usage, experimental results, performance tables, and references. By scanning the text we can identify the key components of the paper:\n",
      "\n",
      "1. **Purpose and Motivation** – The paper addresses the need for generalist agents that can perform complex tasks without heavy pre‑engineering of tools or workflows, citing the rapid evolution of LLMs into autonomous agents.\n",
      "\n",
      "2. **Proposed Solution (ALITA)** – A minimal‑predefinition, maximal‑self‑evolution framework. It uses a manager agent that orchestrates a small set of powerful tools (MCP Brainstorming, ScriptGeneratingTool, CodeRunningTool) and relies on self‑generated “MCPs” (Meta‑Cognitive Plans) to fill functional gaps.\n",
      "\n",
      "3. **Methodology** – The manager agent dynamically selects tools, generates code, runs it in isolated environments, and iteratively refines plans. The system emphasizes isolation, reproducibility, and automatic recovery from failures.\n",
      "\n",
      "4. **Experimental Evaluation** – ALITA is evaluated on the GAIA benchmark. Results show superior performance compared to other agents, achieving 75.15 % pass@1 and 87.27 % pass@3 with Claude‑Sonnet‑4 and GPT‑4o. Tables compare performance across difficulty levels and against GPT‑4o‑mini.\n",
      "\n",
      "5. **Additional Findings** – Reuse of ALITA‑generated MCPs improves performance for other frameworks (Open Deep Research‑smolagents). The paper also discusses tool usage, environment activation, and failure handling.\n",
      "\n",
      "6. **Contextual Details** – The document includes author affiliations, references to related work, and a brief case study example.\n",
      "\n",
      "From these observations, a concise summary can be constructed that captures the motivation, design, key innovations, and empirical results of the ALITA system.\n",
      "\n",
      "[[ ## summary ## ]]\n",
      "The paper “ALITA: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self‑Evolution” presents a lightweight, generalist agent framework that achieves strong performance on complex reasoning tasks without relying on extensive handcrafted tools or workflows. ALITA’s core idea is a manager agent that orchestrates a small set of powerful tools—MCP Brainstorming, ScriptGeneratingTool, and CodeRunningTool—while generating Meta‑Cognitive Plans (MCPs) on the fly to fill functional gaps. The system emphasizes isolated, reproducible execution environments and automatic recovery from failures. Evaluated on the GAIA benchmark, ALITA outperforms many existing agents, achieving 75.15 % pass@1 and 87.27 % pass@3 with Claude‑Sonnet‑4 and GPT‑4o. Performance tables show consistent gains across difficulty levels, and experiments demonstrate that reusing ALITA‑generated MCPs benefits other frameworks. The work highlights how minimal predefinition combined with self‑evolution can enable scalable, autonomous reasoning in large language model agents.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6aa49",
   "metadata": {},
   "source": [
    "## DSPy predict - A zero vector DB example\n",
    "\n",
    "Adding an instruction to the Signature helps us to couch the LLM's reply.\n",
    "\n",
    "> Not recommended because the document will greatly clog the LLM's context window. This code just demonstrates the power of having a long context window and how to use DSPy declarative signatures with instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ac9feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector_db = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "        'document: str, question: str -> answer: str',\n",
    "        instructions='Only use the document to answer the question and nothing else.'\n",
    "    )\n",
    ")\n",
    "\n",
    "question = 'How does ALITA help LLMs to achieve autonomous reasoning?'\n",
    "response = zero_vector_db(question=question, document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8362814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ALITA assists large language models (LLMs) in achieving autonomous reasoning by providing a **generalist agent architecture** that emphasizes:\n",
       "\n",
       "1. **Minimal Predefinition** – ALITA is designed to operate with only a few concise, powerful tools (e.g., MCP Brainstorming, ScriptGeneratingTool, CodeRunningTool) instead of extensive, task‑specific toolkits. This reduces the need for hand‑crafted workflows and allows the LLM to adapt to new tasks more readily.\n",
       "\n",
       "2. **Maximal Self‑Evolution** – The agent can evolve its own strategies and tool usage during execution, enabling it to refine its reasoning process on the fly without external intervention.\n",
       "\n",
       "3. **Scalable Agentic Reasoning** – By combining the above principles, ALITA enables LLMs to plan, execute, and iterate over complex tasks autonomously, achieving performance that surpasses many systems with more complex, handcrafted designs (as demonstrated on the GAIA benchmark).\n",
       "\n",
       "In short, ALITA equips LLMs with a lightweight, self‑adapting framework that streamlines reasoning and execution, thereby fostering true autonomous agent behavior."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response.answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428d0bd",
   "metadata": {},
   "source": [
    "YES!! No vector database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18cc75e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-08-08T22:45:02.097425]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `document` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `answer` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## document ## ]]\n",
      "{document}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Only use the document to answer the question and nothing else.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## document ## ]]\n",
      "Doc ID: 1fa1e383-cfb8-4b11-b488-2e3960d1e606\n",
      "Text: arXiv:2505.20286v1  [cs.AI]  26 May 2025 ALITA : G ENERALIST\n",
      "AGENT ENABLING SCALABLE AGENTIC REASONING WITH MINIMAL PREDEFINITION\n",
      "AND MAXIMAL SELF -EVOLUTION Jiahao Qiu∗1, Xuan Qi∗2, Tongcheng\n",
      "Zhang∗3, Xinzhe Juan3,4, Jiacheng Guo1, Yifu Lu1, Yimin Wang3,4, Zixin\n",
      "Yao1, Qihan Ren3, Xun Jiang5, Xing Zhou5, Dongrui Liu3, Ling Yang1,\n",
      "Yue Wu1, Kaixua...Doc ID: 6d081601-b426-4a8d-bbfb-925213b9487a\n",
      "Text: 1 Introduction \"Simplicity is the ultimate sophistication.\" —\n",
      "Leonardo da Vinci Large language models (LLMs) have rapidly evolved\n",
      "from merely generating text to autonomous agents capable of\n",
      "independently planning and executing complex tasks on behalf of users\n",
      "with limited human oversight [ 2]. These capabilities have enabled a\n",
      "wide range of appl...Doc ID: 8960419c-a737-4468-9de1-342154f6a6ad\n",
      "Text: • We present Alita, a generalist agent that achieves scalable\n",
      "agentic reasoning with a radically simple design. • We empirically\n",
      "demonstrate that Alita, despite using no complex predefined tools and\n",
      "workflows for specific tasks, outperforms many systems with\n",
      "significantly more handcrafted complexity on the GAIA benchmark. We\n",
      "achieve 75.15% pass@...Doc ID: ac1914a6-c96e-4497-b9d4-f3b87a47d114\n",
      "Text: 3 Methods We propose Alita, a generalist agent enabling scalable\n",
      "agentic reasoning with minimal predefinition and maximal self-\n",
      "evolution to tackle diverse and complex tasks. Figure 3 illustrates\n",
      "the framework of Alita. In contrast to generalist agents that\n",
      "typically depend on extensive manually-designed tools and workflows\n",
      "[8, 9], the manager ag...Doc ID: 37d7be38-4ee8-49bc-a33f-09149bccc94d\n",
      "Text: Tool Usage. In contrast to traditional systems that rely on\n",
      "extensive predefined toolkits, the manager agent em- braces Alita’s\n",
      "minimal philosophy by employing concise but powerful toolkits,\n",
      "including MCP Brainstorming, ScriptGeneratingTool and CodeRunningTool.\n",
      "Specifically, MCP Brainstorming detects functional gaps, identi- fies\n",
      "necessary suppl...Doc ID: 85ff2aa7-f99f-4889-a601-43a67528dded\n",
      "Text: of the system. During execution, the environment is explicitly\n",
      "activated prior to invoking the code interpreter, thus ensuring both\n",
      "isolation and reproducibility. In the event of a failure during\n",
      "environment initialization—due to issues such as missing packages,\n",
      "syntax errors in setup scripts, or unavailable dependencies—Alita\n",
      "activates an autom...Doc ID: 79d6f9bd-bd4f-400e-aea4-37b5e417e276\n",
      "Text: framework excels in generating comprehensive reports on complex\n",
      "topics and has shown superior performance on benchmarks. 4.2 Results\n",
      "We run three rounds of testing on GAIA and achieved the best\n",
      "performance on the GAIA leaderboard, surpassing other agent systems.\n",
      "Alita with Claude-Sonnet-4 and GPT-4o achieves 75.15% pass@1 and\n",
      "87.27% pass@3 accur...Doc ID: bdba7133-079f-4f6d-a4a4-de1b206e8fc0\n",
      "Text: 5.1.2 Reuse by Open Deep Research-smolagents We run open Deep\n",
      "Research-smolagents [25] on GAIA with and without Alita-generated MCPs\n",
      "based on GPT-4o. The results are presented in Table 2. From this\n",
      "experiment, we observe that the reuse of Alita-generated MCPs results\n",
      "in better performance compared to the base framework for all\n",
      "difficulty levels....Doc ID: 30336fbe-8713-4af7-835f-7d2f2051fcae\n",
      "Text: Model Configuration Level 1 Level 2 Level 3 Total Alita\n",
      "(Claude-3.7-Sonnet, GPT-4o) 81.13% 75.58% 46.15% 72.73% Alita\n",
      "(GPT-4o-mini) 54.72% 44.19% 19.23% 43.64% Table 4: Comparison of\n",
      "performance between Alita(Claude-3.7-Sonnet,GPT-4o) and\n",
      "Alita(GPT-4o-mini). The results are reported at different GAIA levels:\n",
      "Level 1, Level 2, Level 3, and the av...Doc ID: a416bc55-63b7-4a4a-940b-b7fcde54f691\n",
      "Text: References [1] OpenAI. Introducing deep research. [2] Noam Kolt.\n",
      "Governing ai agents. arXiv preprint arXiv:2501.07913, 2025. [3] Jian\n",
      "Xie, Kai Zhang, Jiangjie Chen, Tinghui Zhu, Renze Lou, Yuandong Tian,\n",
      "Yanghua Xiao, and Yu Su. Travelplanner: A benchmark for real-world\n",
      "planning with language agents. arXiv preprint arXiv:2402.01622, 2024.\n",
      "[4] Ti...Doc ID: 65087bdd-69ec-4321-9308-ff198fa94635\n",
      "Text: [21] Tiantian Gan and Qiyao Sun. Rag-mcp: Mitigating prompt\n",
      "bloat in llm tool selection via retrieval-augmented generation. arXiv\n",
      "preprint arXiv:2505.03275, 2025. [22] Fengfei Sun, Ningke Li, Kailong\n",
      "Wang, and Lorenz Goette. Large language models are overconfident and\n",
      "amplify human bias. 2025. [23] Pan Lu, Hritik Bansal, Tony Xia,\n",
      "Jiacheng Liu, ...Doc ID: 7e077f04-2c4c-4b21-bcf4-429895c7b41b\n",
      "Text: A Detailed Case Study Case Study: YouTube 360 VR Video Subtitle\n",
      "Extraction Question ID: 0512426f-4d28-49f0-be77-06d05daec096 Question:\n",
      "In the YouTube 360 VR video from March 2018 narrated by the voice\n",
      "actor of Lord of the Rings’ Gollum, what number was mentioned by the\n",
      "narrator directly after dinosaurs were first shown in the video? Our\n",
      "Answer: ...\n",
      "\n",
      "[[ ## question ## ]]\n",
      "How does ALITA help LLMs to achieve autonomous reasoning?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## answer ## ]]\n",
      "ALITA assists large language models (LLMs) in achieving autonomous reasoning by providing a **generalist agent architecture** that emphasizes:\n",
      "\n",
      "1. **Minimal Predefinition** – ALITA is designed to operate with only a few concise, powerful tools (e.g., MCP Brainstorming, ScriptGeneratingTool, CodeRunningTool) instead of extensive, task‑specific toolkits. This reduces the need for hand‑crafted workflows and allows the LLM to adapt to new tasks more readily.\n",
      "\n",
      "2. **Maximal Self‑Evolution** – The agent can evolve its own strategies and tool usage during execution, enabling it to refine its reasoning process on the fly without external intervention.\n",
      "\n",
      "3. **Scalable Agentic Reasoning** – By combining the above principles, ALITA enables LLMs to plan, execute, and iterate over complex tasks autonomously, achieving performance that surpasses many systems with more complex, handcrafted designs (as demonstrated on the GAIA benchmark).\n",
      "\n",
      "In short, ALITA equips LLMs with a lightweight, self‑adapting framework that streamlines reasoning and execution, thereby fostering true autonomous agent behavior.  \n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e6bf1",
   "metadata": {},
   "source": [
    "# 2. Programmatic Signatures and how they integrate with the broader LLM ecosystem\n",
    "Let's create an agent with a signature declared using a programmed class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbd443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c981af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dspy-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
